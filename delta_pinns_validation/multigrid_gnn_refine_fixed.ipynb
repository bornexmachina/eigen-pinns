{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaae7b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh...\n",
      "Mesh loaded: 25905 vertices\n",
      "Hierarchy: [1024, 2048, 4096, 25905]\n",
      "  Level 0: 1024 points (nested)\n",
      "  Level 1: 2048 points (nested)\n",
      "  Level 2: 4096 points (nested)\n",
      "  Level 3: 25905 points (nested)\n",
      "\n",
      "LEVEL 0: coarse solving...\n",
      "Coarse eigenvalues: [0.       0.277832 0.500051 0.612778 0.899788 0.972215 1.051292 1.647844\n",
      " 1.937531 1.976983]\n",
      "\n",
      "LEVEL 1: refine 1024 -> 2048, epochs=1500\n",
      "  Computing Laplacian for 2048 points...\n",
      "  Building prolongation operator...\n",
      "  Building kNN graph...\n",
      "  Creating new corrector model (in_dim=13, out_dim=10)...\n",
      "  Training corrector: epochs=1500, lr=0.001, corr_scale=0.01\n",
      "    Epoch    0: Loss=0.949619 (Res=0.000045, Orth=0.094917, Proj=0.000789) U_norm=3.1788 corr_std=0.000474\n",
      "    Epoch  200: Loss=0.284183 (Res=0.000197, Orth=0.028216, Proj=0.052852) U_norm=15.8578 corr_std=0.090114\n",
      "    Epoch  400: Loss=0.003500 (Res=0.000341, Orth=0.000000, Proj=0.090020) U_norm=20.3961 corr_std=0.120646\n",
      "    Epoch  600: Loss=0.002912 (Res=0.000282, Orth=0.000000, Proj=0.089701) U_norm=20.3682 corr_std=0.120463\n",
      "    Epoch  800: Loss=0.002355 (Res=0.000226, Orth=0.000000, Proj=0.089335) U_norm=20.3360 corr_std=0.120304\n",
      "    Epoch 1000: Loss=0.001885 (Res=0.000179, Orth=0.000000, Proj=0.088634) U_norm=20.2676 corr_std=0.119998\n",
      "    Epoch 1200: Loss=0.001525 (Res=0.000143, Orth=0.000000, Proj=0.087857) U_norm=20.1913 corr_std=0.119634\n",
      "    Epoch 1400: Loss=0.001275 (Res=0.000118, Orth=0.000001, Proj=0.087367) U_norm=20.1427 corr_std=0.119396\n",
      "    Epoch 1499: Loss=0.001176 (Res=0.000108, Orth=0.000001, Proj=0.087257) U_norm=20.1334 corr_std=0.119359\n",
      "  Rayleigh-Ritz refinement...\n",
      "  Saved checkpoint: ./checkpoints/level_1_ckpt.pt\n",
      "GNN-refined eigenvalues: [0.031 0.344 0.592 0.693 1.009 1.143 1.247 1.923 2.207 2.402]\n",
      "\n",
      "LEVEL 2: refine 2048 -> 4096, epochs=1000\n",
      "  Computing Laplacian for 4096 points...\n",
      "  Building prolongation operator...\n",
      "  Building kNN graph...\n",
      "  Recreating model to match new input dim (was 26, now 13)...\n",
      "  Frozen first 1 linear layers.\n",
      "  Training corrector: epochs=1000, lr=0.0007937005259840999, corr_scale=0.01\n",
      "    Epoch    0: Loss=0.173959 (Res=0.000053, Orth=0.017336, Proj=0.071030) U_norm=23.9949 corr_std=0.112834\n",
      "    Epoch  200: Loss=0.000772 (Res=0.000067, Orth=0.000000, Proj=0.101500) U_norm=28.3662 corr_std=0.136434\n",
      "    Epoch  400: Loss=0.000743 (Res=0.000064, Orth=0.000000, Proj=0.101442) U_norm=28.3588 corr_std=0.136403\n",
      "    Epoch  600: Loss=0.000722 (Res=0.000062, Orth=0.000000, Proj=0.101353) U_norm=28.3483 corr_std=0.136347\n",
      "    Epoch  800: Loss=0.000701 (Res=0.000060, Orth=0.000000, Proj=0.101287) U_norm=28.3408 corr_std=0.136309\n",
      "    Epoch  999: Loss=0.000681 (Res=0.000058, Orth=0.000000, Proj=0.101236) U_norm=28.3353 corr_std=0.136276\n",
      "  Rayleigh-Ritz refinement...\n",
      "  Saved checkpoint: ./checkpoints/level_2_ckpt.pt\n",
      "GNN-refined eigenvalues: [0.046 0.347 0.617 0.728 1.071 1.217 1.328 2.138 2.361 2.545]\n",
      "\n",
      "LEVEL 3: refine 4096 -> 25905, epochs=800\n",
      "  Computing Laplacian for 25905 points...\n",
      "  Building prolongation operator...\n",
      "  Building kNN graph...\n",
      "  Recreating model to match new input dim (was 26, now 13)...\n",
      "  Frozen first 1 linear layers.\n",
      "  Training corrector: epochs=800, lr=0.0006299605249474366, corr_scale=0.01\n",
      "    Epoch    0: Loss=0.029054 (Res=0.000005, Orth=0.002808, Proj=0.929703) U_norm=69.9083 corr_std=0.135506\n",
      "    Epoch  200: Loss=0.000970 (Res=0.000005, Orth=0.000000, Proj=0.921827) U_norm=69.7381 corr_std=0.134722\n",
      "    Epoch  400: Loss=0.000929 (Res=0.000005, Orth=0.000000, Proj=0.881220) U_norm=68.1695 corr_std=0.131662\n",
      "    Epoch  600: Loss=0.000886 (Res=0.000005, Orth=0.000000, Proj=0.837724) U_norm=66.4513 corr_std=0.128308\n",
      "    Epoch  799: Loss=0.000850 (Res=0.000005, Orth=0.000000, Proj=0.798310) U_norm=64.8468 corr_std=0.125180\n",
      "  Rayleigh-Ritz refinement...\n",
      "  Saved checkpoint: ./checkpoints/level_3_ckpt.pt\n",
      "GNN-refined eigenvalues: [0.053 0.37  0.665 0.748 1.106 1.305 1.44  2.29  2.517 2.67 ]\n",
      "\n",
      "Done. Final eigenvalues: [0.053 0.37  0.665 0.748 1.106 1.305 1.44  2.29  2.517 2.67 ]\n"
     ]
    }
   ],
   "source": [
    "# multigrid_gnn_refine_fixed.py\n",
    "\"\"\"\n",
    "Complete working rewrite of your multigrid + GNN eigen-refinement pipeline.\n",
    "\n",
    "Assumptions:\n",
    " - `Mesh` class exists and Mesh('bunny.obj') loads .verts (n x 3) and .connectivity (triangles).\n",
    " - `robust_laplacian.point_cloud_laplacian(X)` returns (L, M) as scipy sparse matrices where L and M are compatible with eigsh.\n",
    " - scikit-learn, scipy, numpy, matplotlib, torch are installed.\n",
    "\n",
    "Key features:\n",
    " - All classes and functions defined in one file (no missing names).\n",
    " - Stable training: column normalization, small correction scale, normalized losses, grad clipping, configurable weights.\n",
    " - Auto-detect input feature dimension to avoid matmul mismatches.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports (must be available in your environment)\n",
    "from Mesh import Mesh\n",
    "import robust_laplacian\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Utility helpers\n",
    "# ------------------------\n",
    "def sp_to_torch_sparse(A):\n",
    "    \"\"\"Convert scipy sparse matrix to torch.sparse_coo_tensor (CPU or GPU depending on .to(device)).\"\"\"\n",
    "    A = A.tocoo()\n",
    "    indices = np.vstack((A.row, A.col)).astype(np.int64)\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(A.data)\n",
    "    return torch.sparse_coo_tensor(i, v, A.shape).coalesce()\n",
    "\n",
    "\n",
    "def normalize_columns_np(U, eps=1e-12):\n",
    "    \"\"\"Normalize numpy matrix columns to have unit L2 norm. Returns normalized U and norms.\"\"\"\n",
    "    norms = np.linalg.norm(U, axis=0) + eps\n",
    "    return U / norms, norms\n",
    "\n",
    "\n",
    "def normalize_columns_torch(U, eps=1e-12):\n",
    "    \"\"\"Normalize torch tensor columns to have unit L2 norm. Returns normalized U and norms (torch).\"\"\"\n",
    "    norms = torch.norm(U, dim=0) + eps\n",
    "    return U / norms, norms\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Simple per-node corrector (message-passing via neighbor mean + MLP)\n",
    "# ------------------------\n",
    "class SimpleCorrector(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_sizes=(128, 64, 32), dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim * 2  # because we will concat self + neighbor-mean in forward\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if dropout > 0.0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x: [n, in_dim]\n",
    "        edge_index: LongTensor shape [2, n_edges] with (row=target, col=source) semantics\n",
    "        \"\"\"\n",
    "        row, col = edge_index  # both LongTensor\n",
    "        n = x.shape[0]\n",
    "        # aggregate neighbor features: mean aggregator\n",
    "        agg = torch.zeros_like(x)\n",
    "        agg.index_add_(0, row, x[col])\n",
    "        deg = torch.bincount(row, minlength=n).unsqueeze(1).to(x.dtype).to(x.device)\n",
    "        deg = deg.clamp(min=1.0)\n",
    "        agg = agg / deg\n",
    "        h = torch.cat([x, agg], dim=1)  # shape [n, 2*in_dim]\n",
    "        return self.net(h)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Multigrid eigensolver with GNN corrector\n",
    "# ------------------------\n",
    "class MultigridEigensolver:\n",
    "    def __init__(self, device=None, checkpoint_dir=\"./checkpoints\"):\n",
    "        self.device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "        self.model = None\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_mesh(mesh):\n",
    "        centroid = mesh.verts.mean(0)\n",
    "        std_max = mesh.verts.std(0).max() + 1e-12\n",
    "        verts_normalized = (mesh.verts - centroid) / std_max\n",
    "        return Mesh(verts=verts_normalized, connectivity=mesh.connectivity)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_prolongation(X_coarse, X_fine, k=1):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_coarse)\n",
    "        distances, indices = nbrs.kneighbors(X_fine)\n",
    "        n_fine, n_coarse = X_fine.shape[0], X_coarse.shape[0]\n",
    "        rows, cols, vals = [], [], []\n",
    "        for i in range(n_fine):\n",
    "            weights = 1.0 / (distances[i] + 1e-12)\n",
    "            weights /= weights.sum()\n",
    "            for j, idx in enumerate(indices[i]):\n",
    "                rows.append(i)\n",
    "                cols.append(idx)\n",
    "                vals.append(weights[j])\n",
    "        return coo_matrix((vals, (rows, cols)), shape=(n_fine, n_coarse))\n",
    "\n",
    "    @staticmethod\n",
    "    def build_knn_graph(X, k=4):\n",
    "        n_points = X.shape[0]\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1).fit(X)\n",
    "        _, neighbors = nbrs.kneighbors(X)\n",
    "        rows, cols = [], []\n",
    "        for i in range(n_points):\n",
    "            for j in neighbors[i][1:]:\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "        return torch.LongTensor([rows, cols]).to(torch.long)\n",
    "\n",
    "    def solve_eigenvalue_problem(self, X, n_modes):\n",
    "        L, M = robust_laplacian.point_cloud_laplacian(X)\n",
    "        # use eigsh with M as mass\n",
    "        vals, vecs = eigsh(L, k=n_modes, M=M, which='SM')\n",
    "        return vals, np.array(vecs), L, M\n",
    "\n",
    "    # ------------------------\n",
    "    # Core training routine\n",
    "    # ------------------------\n",
    "    def train_gnn(self, model, x_feats, edge_index, U_init, L_fine, M_fine, U_coarse, P,\n",
    "                  n_modes,\n",
    "                  epochs=200,\n",
    "                  lr=1e-3,\n",
    "                  corr_scale=1e-2,\n",
    "                  w_res=10.0,\n",
    "                  w_orth=1.0,\n",
    "                  w_proj=1e-3,\n",
    "                  grad_clip=1.0,\n",
    "                  weight_decay=1e-6,\n",
    "                  log_every=200):\n",
    "        \"\"\"\n",
    "        Train corrector model:\n",
    "          - x_feats: torch.FloatTensor [n_fine, in_dim] on device\n",
    "          - edge_index: torch.LongTensor [2, n_edges] on device\n",
    "          - U_init: numpy array [n_fine, n_modes] (will be normalized inside)\n",
    "          - L_fine, M_fine: scipy sparse matrices\n",
    "          - U_coarse: numpy array [n_coarse, n_modes]\n",
    "          - P: scipy sparse prolongation (n_fine x n_coarse)\n",
    "        Returns U_pred (numpy array [n_fine, n_modes]) - denormalized to original U_init scale.\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "\n",
    "        # Convert sparse matrices to torch sparse on device\n",
    "        L_t = sp_to_torch_sparse(L_fine).to(device)\n",
    "        M_t = sp_to_torch_sparse(M_fine).to(device)\n",
    "        R_t = sp_to_torch_sparse(P.T).to(device)\n",
    "\n",
    "        # Normalize columns of U_init and U_coarse (keep original norms for rescaling)\n",
    "        U_init_normed, uinit_norms = normalize_columns_np(U_init)\n",
    "        U_coarse_normed, ucoarse_norms = normalize_columns_np(U_coarse)\n",
    "\n",
    "        U_init_t = torch.FloatTensor(U_init_normed).to(device)   # [n_fine, n_modes]\n",
    "        U_coarse_t = torch.FloatTensor(U_coarse_normed).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        n_fine = U_init_t.shape[0]\n",
    "        n_coarse = U_coarse_t.shape[0]\n",
    "        denom_res = float(max(1, n_fine * n_modes))\n",
    "        denom_proj = float(max(1, n_coarse * n_modes))\n",
    "        I = torch.eye(n_modes, device=device)\n",
    "\n",
    "        model.train()\n",
    "        for ep in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            corr_raw = model(x_feats, edge_index)  # [n_fine, n_modes]\n",
    "            corr = corr_scale * corr_raw\n",
    "            U_pred = U_init_t + corr\n",
    "\n",
    "            # Rayleigh-related tensors\n",
    "            Lu = torch.sparse.mm(L_t, U_pred)\n",
    "            Mu = torch.sparse.mm(M_t, U_pred)\n",
    "            num = torch.sum(U_pred * Lu, dim=0)\n",
    "            den = torch.sum(U_pred * Mu, dim=0) + 1e-12\n",
    "            lambdas = num / den\n",
    "\n",
    "            # Residual loss (normalized)\n",
    "            res = Lu - Mu * lambdas.unsqueeze(0)\n",
    "            L_res = torch.sum(res**2) / denom_res\n",
    "\n",
    "            # Orthonormality loss (M-weighted Gram)\n",
    "            MUt = torch.sparse.mm(M_t, U_pred)\n",
    "            Gram = U_pred.t() @ MUt\n",
    "            L_orth = torch.sum((Gram - I)**2) / (n_modes * n_modes)\n",
    "\n",
    "            # Projection loss\n",
    "            proj = torch.sparse.mm(R_t, U_pred)\n",
    "            L_proj = torch.sum((proj - U_coarse_t)**2) / denom_proj\n",
    "\n",
    "            loss = w_res * L_res + w_orth * L_orth + w_proj * L_proj\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (ep % log_every == 0) or (ep == epochs - 1):\n",
    "                with torch.no_grad():\n",
    "                    u_norm = float(U_pred.norm().cpu().item())\n",
    "                    corr_std = float(corr.std().cpu().item())\n",
    "                print(f\"    Epoch {ep:4d}: Loss={loss.item():.6f} (Res={L_res.item():.6f}, Orth={L_orth.item():.6f}, Proj={L_proj.item():.6f}) U_norm={u_norm:.4f} corr_std={corr_std:.6f}\")\n",
    "\n",
    "        # Denormalize: multiply columns by original column norms of U_init\n",
    "        U_pred_np = U_pred.detach().cpu().numpy() * uinit_norms.reshape(1, -1)\n",
    "        return U_pred_np\n",
    "\n",
    "    # ------------------------\n",
    "    # Rayleigh-Ritz refinement\n",
    "    # ------------------------\n",
    "    def refine_eigenvectors(self, U_pred, L_fine, M_fine):\n",
    "        L_t = sp_to_torch_sparse(L_fine).to(self.device)\n",
    "        M_t = sp_to_torch_sparse(M_fine).to(self.device)\n",
    "        U = torch.FloatTensor(U_pred).to(self.device)\n",
    "        A = (U.t() @ torch.sparse.mm(L_t, U)).cpu().numpy()\n",
    "        B = (U.t() @ torch.sparse.mm(M_t, U)).cpu().numpy()\n",
    "        vals, C = eigh(A, B)\n",
    "        U_refined = U.cpu().numpy() @ C\n",
    "        return vals, U_refined\n",
    "\n",
    "    # ------------------------\n",
    "    # Refine one level (coarse -> fine)\n",
    "    # ------------------------\n",
    "    def refine_level(self, X_coarse, U_coarse, X_fine, n_modes,\n",
    "                     hidden_sizes=(128, 64, 32),\n",
    "                     dropout=0.0,\n",
    "                     k_neighbors=4,\n",
    "                     epochs=200,\n",
    "                     lr=1e-3,\n",
    "                     corr_scale=1e-2,\n",
    "                     w_res=10.0,\n",
    "                     w_orth=1.0,\n",
    "                     w_proj=1e-3,\n",
    "                     freeze_layers=0,\n",
    "                     checkpoint_name=None):\n",
    "        \"\"\"\n",
    "        Single-level refinement.\n",
    "        - Automatically sets input dim from features.\n",
    "        - Creates model if not existing; reuses and optionally freezes layers if existing.\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        print(f\"  Computing Laplacian for {X_fine.shape[0]} points...\")\n",
    "        L_fine, M_fine = robust_laplacian.point_cloud_laplacian(X_fine)\n",
    "\n",
    "        print(\"  Building prolongation operator...\")\n",
    "        P = self.build_prolongation(X_coarse, X_fine, k=1)\n",
    "\n",
    "        print(\"  Building kNN graph...\")\n",
    "        edge_index = self.build_knn_graph(X_fine, k=k_neighbors).to(device)\n",
    "\n",
    "        # Build U_init on fine grid\n",
    "        U_init = P @ U_coarse  # shape [n_fine, n_modes]\n",
    "\n",
    "        # Build features: coords + U_init (we pass raw U_init; normalization happens inside train_gnn)\n",
    "        x_feats = torch.FloatTensor(np.hstack([X_fine, U_init])).to(device)\n",
    "\n",
    "        in_dim = x_feats.shape[1]\n",
    "        out_dim = n_modes\n",
    "\n",
    "        if self.model is None:\n",
    "            print(f\"  Creating new corrector model (in_dim={in_dim}, out_dim={out_dim})...\")\n",
    "            self.model = SimpleCorrector(in_dim, out_dim, hidden_sizes=hidden_sizes, dropout=dropout).to(device)\n",
    "        else:\n",
    "            # If model exists but input dimension changed, re-create model to match new in_dim\n",
    "            # (safer than trying to partially load weights with mismatched shapes)\n",
    "            existing_in_dim = None\n",
    "            # try to infer existing in_dim by checking first Linear in model.net if present\n",
    "            for m in self.model.net:\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    existing_in_dim = m.in_features\n",
    "                    break\n",
    "            if existing_in_dim != in_dim:\n",
    "                print(f\"  Recreating model to match new input dim (was {existing_in_dim}, now {in_dim})...\")\n",
    "                # Optionally copy weights for layers that match by size\n",
    "                old_state = self.model.state_dict()\n",
    "                self.model = SimpleCorrector(in_dim, out_dim, hidden_sizes=hidden_sizes, dropout=dropout).to(device)\n",
    "                # attempt to copy subset of weights where shapes match\n",
    "                new_state = self.model.state_dict()\n",
    "                for k, v in old_state.items():\n",
    "                    if k in new_state and old_state[k].shape == new_state[k].shape:\n",
    "                        new_state[k] = old_state[k]\n",
    "                self.model.load_state_dict(new_state)\n",
    "\n",
    "        # Optionally freeze first few linear layers (count of Linear modules)\n",
    "        if freeze_layers > 0:\n",
    "            linear_count = 0\n",
    "            for module in self.model.net:\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    linear_count += 1\n",
    "                    if linear_count <= freeze_layers:\n",
    "                        for p in module.parameters():\n",
    "                            p.requires_grad = False\n",
    "            print(f\"  Frozen first {freeze_layers} linear layers.\")\n",
    "\n",
    "        print(f\"  Training corrector: epochs={epochs}, lr={lr}, corr_scale={corr_scale}\")\n",
    "        U_pred = self.train_gnn(self.model, x_feats, edge_index, U_init, L_fine, M_fine, U_coarse, P,\n",
    "                                n_modes,\n",
    "                                epochs=epochs,\n",
    "                                lr=lr,\n",
    "                                corr_scale=corr_scale,\n",
    "                                w_res=w_res,\n",
    "                                w_orth=w_orth,\n",
    "                                w_proj=w_proj)\n",
    "\n",
    "        print(\"  Rayleigh-Ritz refinement...\")\n",
    "        lambda_refined, U_refined = self.refine_eigenvectors(U_pred, L_fine, M_fine)\n",
    "\n",
    "        if checkpoint_name is not None:\n",
    "            ckpt = {\"model_state\": self.model.state_dict(), \"lambda_refined\": lambda_refined}\n",
    "            torch.save(ckpt, os.path.join(self.checkpoint_dir, checkpoint_name))\n",
    "            print(f\"  Saved checkpoint: {os.path.join(self.checkpoint_dir, checkpoint_name)}\")\n",
    "\n",
    "        return lambda_refined, U_refined, L_fine, M_fine\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Visualization helper\n",
    "# ------------------------\n",
    "def visualize_mesh(mesh, title='Mesh Visualization', highlight_indices=None, show=True):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.plot_trisurf(mesh.verts[:, 0], mesh.verts[:, 1], mesh.verts[:, 2],\n",
    "                    triangles=mesh.connectivity, alpha=0.35)\n",
    "    if highlight_indices is not None:\n",
    "        hv = mesh.verts[highlight_indices]\n",
    "        ax.scatter(hv[:, 0], hv[:, 1], hv[:, 2], s=6, label=f\"{len(highlight_indices)} pts\")\n",
    "        ax.legend()\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(elev=120, azim=-90)\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Main script\n",
    "# ------------------------\n",
    "def main():\n",
    "    mesh_path = \"face.obj\"\n",
    "    n_modes = 10\n",
    "    hidden_sizes = (128, 128, 128)\n",
    "    dropout = 0.0\n",
    "\n",
    "    # schedule and hyperparams\n",
    "    epochs_schedule = {0: 0, 1: 1500, 2: 1000, 3: 800, 4: 800}\n",
    "    #hierarchy = [128, 512, 1024]  # final level will append full\n",
    "    hierarchy = [1024, 2048, 4096]  # final level will append full\n",
    "    k_neighbors = 4\n",
    "    lr_start = 1e-3\n",
    "    lr_min = 5e-4\n",
    "    corr_scale = 1e-2\n",
    "    w_res = 10.0\n",
    "    w_orth = 10.0\n",
    "    w_proj = 1e-3\n",
    "    freeze_schedule = {1: 0, 2: 1, 3: 1, 4: 2}\n",
    "\n",
    "    print(\"Loading mesh...\")\n",
    "    mesh = Mesh(mesh_path)\n",
    "    mesh = MultigridEigensolver.normalize_mesh(mesh)\n",
    "    X_full = mesh.verts\n",
    "    n_total = X_full.shape[0]\n",
    "    print(f\"Mesh loaded: {n_total} vertices\")\n",
    "\n",
    "    hierarchy = [n for n in hierarchy if n <= n_total]\n",
    "    if hierarchy[-1] != n_total:\n",
    "        hierarchy.append(n_total)\n",
    "    print(\"Hierarchy:\", hierarchy)\n",
    "\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    all_idx = np.arange(n_total)\n",
    "    rng.shuffle(all_idx)\n",
    "    indices_per_level = {}\n",
    "    for i, n_points in enumerate(hierarchy):\n",
    "        indices_per_level[i] = all_idx[:n_points].copy()\n",
    "        print(f\"  Level {i}: {n_points} points (nested)\")\n",
    "\n",
    "    solver = MultigridEigensolver()\n",
    "\n",
    "    # Level 0 coarse solve\n",
    "    idx0 = indices_per_level[0]\n",
    "    X0 = X_full[idx0]\n",
    "    print(\"\\nLEVEL 0: coarse solving...\")\n",
    "    lambda_cur, U_cur, L_cur, M_cur = solver.solve_eigenvalue_problem(X0, n_modes)\n",
    "    print(\"Coarse eigenvalues:\", np.round(lambda_cur, 6))\n",
    "\n",
    "    # iterative refinement\n",
    "    for level in range(1, len(hierarchy)):\n",
    "        idx_coarse = indices_per_level[level - 1]\n",
    "        idx_fine = indices_per_level[level]\n",
    "        Xc = X_full[idx_coarse]\n",
    "        Xf = X_full[idx_fine]\n",
    "        epochs = epochs_schedule.get(level, 1000)\n",
    "\n",
    "        print(f\"\\nLEVEL {level}: refine {Xc.shape[0]} -> {Xf.shape[0]}, epochs={epochs}\")\n",
    "        freeze_layers = freeze_schedule.get(level, 0)\n",
    "\n",
    "        total_levels = len(hierarchy)\n",
    "        decay = (level - 1) / max(1, total_levels - 1)\n",
    "        lr = lr_start * ((lr_min / lr_start) ** decay)\n",
    "\n",
    "        lambda_cur, U_cur, L_cur, M_cur = solver.refine_level(\n",
    "            Xc, U_cur, Xf, n_modes,\n",
    "            hidden_sizes=hidden_sizes,\n",
    "            dropout=dropout,\n",
    "            k_neighbors=k_neighbors,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            corr_scale=corr_scale,\n",
    "            w_res=w_res,\n",
    "            w_orth=w_orth,\n",
    "            w_proj=w_proj,\n",
    "            freeze_layers=freeze_layers,\n",
    "            checkpoint_name=f\"level_{level}_ckpt.pt\"\n",
    "        )\n",
    "\n",
    "        print(\"GNN-refined eigenvalues:\", np.round(lambda_cur, 3))\n",
    "\n",
    "        # exact eigenvalues for verification\n",
    "        #print(\"  computing exact eigenvalues for verification...\")\n",
    "        #lambda_exact, _, _, _ = solver.solve_eigenvalue_problem(Xf, n_modes)\n",
    "        #rel_err = np.abs(lambda_cur - lambda_exact) / (np.abs(lambda_exact) + 1e-12)\n",
    "        #print(\"  Exact eigenvalues:\", np.round(lambda_exact, 6))\n",
    "        #print(\"  Relative errors:  \", np.round(rel_err, 6))\n",
    "\n",
    "    print(\"\\nDone. Final eigenvalues:\", np.round(lambda_cur, 3))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc77de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
