{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d2e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh...\n",
      "Computing Laplacian...\n",
      "Computing eigenvalues (reference)...\n",
      "\n",
      "=== Matrix Conditioning ===\n",
      "Regularization: ε=0.0001\n",
      "Condition number: 1.47e+05\n",
      "Scaling factor: 1.58e+02\n",
      "\n",
      "=== Initializing Model ===\n",
      "Parameters: 128,821\n",
      "Fourier features: True\n",
      "Architecture: [256, 256, 128, 128] -> 50\n",
      "\n",
      "=== Unsupervised Mode: No pre-training ===\n",
      "Model will discover eigenmodes from scratch using only K and M matrices\n",
      "\n",
      "================================================================================\n",
      "TRAINING START\n",
      "================================================================================\n",
      "Epochs: 150,000 | Device: cuda\n",
      "Stage 1: 0-50,000 (orthogonality focus)\n",
      "Stage 2: 50,000-150,000 (eigenvalue tuning)\n",
      "================================================================================\n",
      "\n",
      "[Stage1] Epoch      1 | LR=0.010000\n",
      "  Loss=500.001621 | λ₁=1.55e-11 | Trace=0.000\n",
      "  Orth=7.01e+00 | OffDiag=4.61e-09\n",
      "  MeanRelErr=31077915.3729% | MedianRelErr=99.5882%\n",
      "  λ∈[0.001559, 0.036197] | Spread=0.034638\n",
      "\n",
      "[Stage1] Epoch   2000 | LR=0.009055\n",
      "  Loss=377.213065 | λ₁=1.75e-06 | Trace=11.711\n",
      "  Orth=5.63e+00 | OffDiag=8.37e-02\n",
      "  MeanRelErr=26164066.2776% | MedianRelErr=99.3287%\n",
      "  λ∈[0.001313, 0.949928] | Spread=0.948616\n",
      "\n",
      "[Stage1] Epoch   4000 | LR=0.006580\n",
      "  Loss=375.031444 | λ₁=1.61e-08 | Trace=12.719\n",
      "  Orth=5.57e+00 | OffDiag=9.78e-02\n",
      "  MeanRelErr=3210654.8829% | MedianRelErr=99.6493%\n",
      "  λ∈[0.000161, 1.002557] | Spread=1.002395\n",
      "\n",
      "  ✓ New best model saved (loss=375.504877)\n",
      "[Stage1] Epoch   6000 | LR=0.003520\n",
      "  Loss=372.166641 | λ₁=9.93e-09 | Trace=12.271\n",
      "  Orth=5.57e+00 | OffDiag=1.45e-02\n",
      "  MeanRelErr=2061757.0057% | MedianRelErr=99.8689%\n",
      "  λ∈[0.000103, 0.990583] | Spread=0.990480\n",
      "\n",
      "[Stage1] Epoch   8000 | LR=0.001045\n",
      "  Loss=371.997739 | λ₁=8.97e-09 | Trace=12.338\n",
      "  Orth=5.57e+00 | OffDiag=1.80e-03\n",
      "  MeanRelErr=2034003.2174% | MedianRelErr=99.9117%\n",
      "  λ∈[0.000102, 0.994885] | Spread=0.994783\n",
      "\n",
      "[Stage1] Epoch  10000 | LR=0.010000\n",
      "  Loss=371.965789 | λ₁=1.72e-08 | Trace=12.414\n",
      "  Orth=5.57e+00 | OffDiag=3.22e-04\n",
      "  MeanRelErr=2614961.3011% | MedianRelErr=99.9055%\n",
      "  λ∈[0.000131, 1.001025] | Spread=1.000894\n",
      "  First 5 - Pred: [0.000131 0.000133 0.000134 0.000134 0.000135]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.932502 0.958436 0.978739 0.991931 1.001025]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "  ✓ New best model saved (loss=371.965789)\n",
      "[Stage1] Epoch  12000 | LR=0.009758\n",
      "  Loss=376.704336 | λ₁=4.14e-08 | Trace=11.577\n",
      "  Orth=5.63e+00 | OffDiag=1.53e-01\n",
      "  MeanRelErr=5440000.8534% | MedianRelErr=99.6050%\n",
      "  λ∈[0.000273, 0.921286] | Spread=0.921013\n",
      "\n",
      "[Stage1] Epoch  14000 | LR=0.009055\n",
      "  Loss=375.859121 | λ₁=1.13e-08 | Trace=11.741\n",
      "  Orth=5.62e+00 | OffDiag=1.44e-01\n",
      "  MeanRelErr=3272616.6589% | MedianRelErr=99.7057%\n",
      "  λ∈[0.000164, 0.967216] | Spread=0.967052\n",
      "\n",
      "[Stage1] Epoch  16000 | LR=0.007960\n",
      "  Loss=373.125625 | λ₁=3.46e-09 | Trace=11.970\n",
      "  Orth=5.59e+00 | OffDiag=6.15e-02\n",
      "  MeanRelErr=1748041.1110% | MedianRelErr=99.7873%\n",
      "  λ∈[0.000088, 1.021597] | Spread=1.021509\n",
      "\n",
      "[Stage1] Epoch  18000 | LR=0.006580\n",
      "  Loss=373.563720 | λ₁=5.35e-09 | Trace=12.041\n",
      "  Orth=5.59e+00 | OffDiag=7.43e-02\n",
      "  MeanRelErr=2046208.8407% | MedianRelErr=99.8453%\n",
      "  λ∈[0.000103, 0.979959] | Spread=0.979856\n",
      "\n",
      "[Stage1] Epoch  20000 | LR=0.005050\n",
      "  Loss=372.424525 | λ₁=2.13e-09 | Trace=12.021\n",
      "  Orth=5.58e+00 | OffDiag=1.81e-02\n",
      "  MeanRelErr=1112853.2456% | MedianRelErr=99.8835%\n",
      "  λ∈[0.000056, 0.973138] | Spread=0.973082\n",
      "  First 5 - Pred: [5.60e-05 9.00e-05 9.20e-05 9.70e-05 1.11e-04]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.901936 0.940631 0.947923 0.96036  0.973138]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage1] Epoch  22000 | LR=0.003520\n",
      "  Loss=372.125270 | λ₁=1.37e-10 | Trace=12.139\n",
      "  Orth=5.57e+00 | OffDiag=8.16e-03\n",
      "  MeanRelErr=321937.6207% | MedianRelErr=99.9201%\n",
      "  λ∈[0.000016, 0.984473] | Spread=0.984457\n",
      "\n",
      "[Stage1] Epoch  24000 | LR=0.002140\n",
      "  Loss=372.061974 | λ₁=5.88e-10 | Trace=12.207\n",
      "  Orth=5.57e+00 | OffDiag=4.43e-03\n",
      "  MeanRelErr=518977.0030% | MedianRelErr=99.9214%\n",
      "  λ∈[0.000026, 0.989387] | Spread=0.989361\n",
      "\n",
      "[Stage1] Epoch  26000 | LR=0.001045\n",
      "  Loss=372.011343 | λ₁=6.01e-11 | Trace=12.264\n",
      "  Orth=5.57e+00 | OffDiag=2.15e-03\n",
      "  MeanRelErr=187281.5275% | MedianRelErr=99.9518%\n",
      "  λ∈[0.000009, 0.993709] | Spread=0.993700\n",
      "\n",
      "[Stage1] Epoch  28000 | LR=0.000342\n",
      "  Loss=371.970141 | λ₁=2.34e-11 | Trace=12.370\n",
      "  Orth=5.57e+00 | OffDiag=4.35e-04\n",
      "  MeanRelErr=101959.1034% | MedianRelErr=99.9556%\n",
      "  λ∈[0.000005, 0.997139] | Spread=0.997134\n",
      "\n",
      "[Stage1] Epoch  30000 | LR=0.010000\n",
      "  Loss=371.964363 | λ₁=9.78e-12 | Trace=12.425\n",
      "  Orth=5.57e+00 | OffDiag=2.14e-04\n",
      "  MeanRelErr=64485.8656% | MedianRelErr=99.9560%\n",
      "  λ∈[0.000003, 0.998174] | Spread=0.998171\n",
      "  First 5 - Pred: [3.e-06 3.e-06 4.e-06 4.e-06 4.e-06]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.932546 0.959549 0.978787 0.997509 0.998174]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage1] Epoch  32000 | LR=0.009939\n",
      "  Loss=375.065891 | λ₁=5.38e-09 | Trace=12.352\n",
      "  Orth=5.59e+00 | OffDiag=1.23e-01\n",
      "  MeanRelErr=2256554.2245% | MedianRelErr=99.5899%\n",
      "  λ∈[0.000113, 1.001192] | Spread=1.001079\n",
      "\n",
      "[Stage1] Epoch  34000 | LR=0.009758\n",
      "  Loss=374.654429 | λ₁=1.01e-09 | Trace=12.294\n",
      "  Orth=5.59e+00 | OffDiag=7.84e-02\n",
      "  MeanRelErr=949663.5135% | MedianRelErr=99.8101%\n",
      "  λ∈[0.000048, 1.068336] | Spread=1.068289\n",
      "\n",
      "[Stage1] Epoch  36000 | LR=0.009460\n",
      "  Loss=373.202059 | λ₁=8.53e-10 | Trace=11.892\n",
      "  Orth=5.59e+00 | OffDiag=5.99e-02\n",
      "  MeanRelErr=836489.2003% | MedianRelErr=99.8295%\n",
      "  λ∈[0.000042, 0.967564] | Spread=0.967522\n",
      "\n",
      "[Stage1] Epoch  38000 | LR=0.009055\n",
      "  Loss=373.910721 | λ₁=7.42e-10 | Trace=12.039\n",
      "  Orth=5.60e+00 | OffDiag=9.14e-02\n",
      "  MeanRelErr=761662.4167% | MedianRelErr=99.8172%\n",
      "  λ∈[0.000038, 0.965720] | Spread=0.965682\n",
      "\n",
      "[Stage1] Epoch  40000 | LR=0.008550\n",
      "  Loss=372.781757 | λ₁=7.21e-09 | Trace=12.098\n",
      "  Orth=5.58e+00 | OffDiag=3.67e-02\n",
      "  MeanRelErr=2134226.2319% | MedianRelErr=99.8490%\n",
      "  λ∈[0.000107, 0.979829] | Spread=0.979722\n",
      "  First 5 - Pred: [0.000107 0.000116 0.000118 0.000119 0.000156]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.905676 0.907711 0.926972 0.947256 0.979829]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage1] Epoch  42000 | LR=0.007960\n",
      "  Loss=373.304511 | λ₁=3.78e-10 | Trace=12.005\n",
      "  Orth=5.59e+00 | OffDiag=5.70e-02\n",
      "  MeanRelErr=596218.8366% | MedianRelErr=99.8430%\n",
      "  λ∈[0.000030, 0.969336] | Spread=0.969306\n",
      "\n",
      "[Stage1] Epoch  44000 | LR=0.007297\n",
      "  Loss=372.550579 | λ₁=5.16e-10 | Trace=11.820\n",
      "  Orth=5.59e+00 | OffDiag=2.07e-02\n",
      "  MeanRelErr=675328.2122% | MedianRelErr=99.8616%\n",
      "  λ∈[0.000034, 0.950791] | Spread=0.950757\n",
      "\n",
      "[Stage1] Epoch  46000 | LR=0.006580\n",
      "  Loss=372.512826 | λ₁=3.46e-09 | Trace=12.134\n",
      "  Orth=5.58e+00 | OffDiag=2.95e-02\n",
      "  MeanRelErr=1661041.0236% | MedianRelErr=99.8619%\n",
      "  λ∈[0.000083, 1.043874] | Spread=1.043791\n",
      "\n",
      "[Stage1] Epoch  48000 | LR=0.005824\n",
      "  Loss=372.727255 | λ₁=1.15e-09 | Trace=11.894\n",
      "  Orth=5.59e+00 | OffDiag=2.90e-02\n",
      "  MeanRelErr=870103.0743% | MedianRelErr=99.8600%\n",
      "  λ∈[0.000044, 0.987457] | Spread=0.987413\n",
      "\n",
      "[Stage1] Epoch  50000 | LR=0.005050\n",
      "  Loss=372.183278 | λ₁=4.97e-09 | Trace=12.120\n",
      "  Orth=5.57e+00 | OffDiag=1.13e-02\n",
      "  MeanRelErr=1554073.7981% | MedianRelErr=99.8558%\n",
      "  λ∈[0.000078, 0.987770] | Spread=0.987692\n",
      "  First 5 - Pred: [7.80e-05 9.10e-05 1.07e-04 1.50e-04 1.52e-04]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.921436 0.955367 0.973226 0.984741 0.98777 ]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ENTERING STAGE 2: Fine-tuning eigenvalues\n",
      "================================================================================\n",
      "\n",
      "[Stage2] Epoch  52000 | LR=0.000999\n",
      "  Loss=229.674568 | λ₁=1.17e-06 | Trace=0.398\n",
      "  Orth=6.72e+00 | OffDiag=3.26e-02\n",
      "  MeanRelErr=21444153.0870% | MedianRelErr=99.9287%\n",
      "  λ∈[0.001076, 0.123200] | Spread=0.122124\n",
      "\n",
      "[Stage2] Epoch  54000 | LR=0.000996\n",
      "  Loss=229.969291 | λ₁=8.89e-07 | Trace=0.258\n",
      "  Orth=6.71e+00 | OffDiag=1.21e-02\n",
      "  MeanRelErr=18856924.8714% | MedianRelErr=99.9569%\n",
      "  λ∈[0.000946, 0.090172] | Spread=0.089226\n",
      "\n",
      "  ✓ New best model saved (loss=229.831500)\n",
      "[Stage2] Epoch  56000 | LR=0.000992\n",
      "  Loss=231.195128 | λ₁=6.97e-07 | Trace=0.227\n",
      "  Orth=6.73e+00 | OffDiag=8.68e-03\n",
      "  MeanRelErr=16610957.0127% | MedianRelErr=99.9481%\n",
      "  λ∈[0.000833, 0.078805] | Spread=0.077971\n",
      "\n",
      "[Stage2] Epoch  58000 | LR=0.000986\n",
      "  Loss=230.245559 | λ₁=7.17e-07 | Trace=0.211\n",
      "  Orth=6.72e+00 | OffDiag=7.82e-03\n",
      "  MeanRelErr=16964921.7390% | MedianRelErr=99.9601%\n",
      "  λ∈[0.000851, 0.066339] | Spread=0.065488\n",
      "\n",
      "[Stage2] Epoch  60000 | LR=0.000978\n",
      "  Loss=229.239891 | λ₁=1.17e-06 | Trace=0.206\n",
      "  Orth=6.72e+00 | OffDiag=8.23e-03\n",
      "  MeanRelErr=21661732.4603% | MedianRelErr=99.9539%\n",
      "  λ∈[0.001087, 0.062469] | Spread=0.061382\n",
      "  First 5 - Pred: [0.001087 0.001088 0.00109  0.001093 0.001094]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.013201 0.013305 0.013314 0.022339 0.062469]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "  ✓ New best model saved (loss=229.239891)\n",
      "[Stage2] Epoch  62000 | LR=0.000968\n",
      "  Loss=229.456315 | λ₁=1.21e-06 | Trace=0.207\n",
      "  Orth=6.72e+00 | OffDiag=8.28e-03\n",
      "  MeanRelErr=21998871.8446% | MedianRelErr=99.9542%\n",
      "  λ∈[0.001104, 0.060137] | Spread=0.059033\n",
      "\n",
      "[Stage2] Epoch  64000 | LR=0.000957\n",
      "  Loss=229.374018 | λ₁=1.24e-06 | Trace=0.200\n",
      "  Orth=6.72e+00 | OffDiag=8.22e-03\n",
      "  MeanRelErr=22155856.4141% | MedianRelErr=99.9531%\n",
      "  λ∈[0.001112, 0.061017] | Spread=0.059905\n",
      "\n",
      "[Stage2] Epoch  66000 | LR=0.000944\n",
      "  Loss=229.562386 | λ₁=1.15e-06 | Trace=0.211\n",
      "  Orth=6.71e+00 | OffDiag=7.92e-03\n",
      "  MeanRelErr=21332091.8779% | MedianRelErr=99.9527%\n",
      "  λ∈[0.001070, 0.065265] | Spread=0.064195\n",
      "\n",
      "[Stage2] Epoch  68000 | LR=0.000930\n",
      "  Loss=229.600524 | λ₁=1.24e-06 | Trace=0.202\n",
      "  Orth=6.72e+00 | OffDiag=8.28e-03\n",
      "  MeanRelErr=22164180.7765% | MedianRelErr=99.9532%\n",
      "  λ∈[0.001112, 0.060511] | Spread=0.059399\n",
      "\n",
      "[Stage2] Epoch  70000 | LR=0.000914\n",
      "  Loss=229.923661 | λ₁=7.25e-07 | Trace=0.196\n",
      "  Orth=6.72e+00 | OffDiag=8.05e-03\n",
      "  MeanRelErr=16979969.6663% | MedianRelErr=99.9569%\n",
      "  λ∈[0.000852, 0.059568] | Spread=0.058716\n",
      "  First 5 - Pred: [0.000852 0.000864 0.000867 0.000867 0.000868]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.012586 0.012819 0.012896 0.023405 0.059568]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage2] Epoch  72000 | LR=0.000897\n",
      "  Loss=229.398165 | λ₁=6.95e-07 | Trace=0.199\n",
      "  Orth=6.72e+00 | OffDiag=8.05e-03\n",
      "  MeanRelErr=16646141.7237% | MedianRelErr=99.9618%\n",
      "  λ∈[0.000835, 0.061626] | Spread=0.060791\n",
      "\n",
      "[Stage2] Epoch  74000 | LR=0.000878\n",
      "  Loss=229.720004 | λ₁=5.39e-07 | Trace=0.205\n",
      "  Orth=6.71e+00 | OffDiag=8.63e-03\n",
      "  MeanRelErr=14687012.3781% | MedianRelErr=99.9539%\n",
      "  λ∈[0.000737, 0.056778] | Spread=0.056041\n",
      "\n",
      "[Stage2] Epoch  76000 | LR=0.000858\n",
      "  Loss=229.349484 | λ₁=6.32e-07 | Trace=0.204\n",
      "  Orth=6.72e+00 | OffDiag=8.07e-03\n",
      "  MeanRelErr=15823765.2494% | MedianRelErr=99.9628%\n",
      "  λ∈[0.000794, 0.066430] | Spread=0.065636\n",
      "\n",
      "[Stage2] Epoch  78000 | LR=0.000837\n",
      "  Loss=229.364514 | λ₁=6.65e-07 | Trace=0.219\n",
      "  Orth=6.72e+00 | OffDiag=8.96e-03\n",
      "  MeanRelErr=16205304.9466% | MedianRelErr=99.9602%\n",
      "  λ∈[0.000813, 0.079035] | Spread=0.078222\n",
      "\n",
      "[Stage2] Epoch  80000 | LR=0.000815\n",
      "  Loss=229.932336 | λ₁=6.82e-07 | Trace=0.194\n",
      "  Orth=6.72e+00 | OffDiag=7.12e-03\n",
      "  MeanRelErr=16482004.8291% | MedianRelErr=99.9550%\n",
      "  λ∈[0.000827, 0.060553] | Spread=0.059726\n",
      "  First 5 - Pred: [0.000827 0.000846 0.000861 0.000867 0.000876]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.013508 0.015833 0.015846 0.022704 0.060553]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage2] Epoch  82000 | LR=0.000791\n",
      "  Loss=230.035459 | λ₁=6.74e-07 | Trace=0.196\n",
      "  Orth=6.72e+00 | OffDiag=7.54e-03\n",
      "  MeanRelErr=16345085.3042% | MedianRelErr=99.9574%\n",
      "  λ∈[0.000820, 0.062700] | Spread=0.061880\n",
      "\n",
      "[Stage2] Epoch  84000 | LR=0.000767\n",
      "  Loss=229.472983 | λ₁=5.92e-07 | Trace=0.197\n",
      "  Orth=6.72e+00 | OffDiag=7.84e-03\n",
      "  MeanRelErr=15300349.1410% | MedianRelErr=99.9570%\n",
      "  λ∈[0.000768, 0.061229] | Spread=0.060462\n",
      "\n",
      "[Stage2] Epoch  86000 | LR=0.000742\n",
      "  Loss=229.482611 | λ₁=5.00e-07 | Trace=0.193\n",
      "  Orth=6.72e+00 | OffDiag=7.34e-03\n",
      "  MeanRelErr=14063577.0587% | MedianRelErr=99.9615%\n",
      "  λ∈[0.000706, 0.063288] | Spread=0.062583\n",
      "\n",
      "[Stage2] Epoch  88000 | LR=0.000716\n",
      "  Loss=230.156745 | λ₁=5.46e-07 | Trace=0.193\n",
      "  Orth=6.72e+00 | OffDiag=7.27e-03\n",
      "  MeanRelErr=14687235.3055% | MedianRelErr=99.9566%\n",
      "  λ∈[0.000737, 0.060831] | Spread=0.060094\n",
      "\n",
      "[Stage2] Epoch  90000 | LR=0.000689\n",
      "  Loss=229.424829 | λ₁=5.68e-07 | Trace=0.199\n",
      "  Orth=6.72e+00 | OffDiag=7.64e-03\n",
      "  MeanRelErr=15037696.5687% | MedianRelErr=99.9615%\n",
      "  λ∈[0.000755, 0.061746] | Spread=0.060992\n",
      "  First 5 - Pred: [0.000755 0.000755 0.000756 0.000757 0.00076 ]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.012234 0.014838 0.014842 0.022998 0.061746]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage2] Epoch  92000 | LR=0.000662\n",
      "  Loss=235.099099 | λ₁=6.77e-07 | Trace=0.256\n",
      "  Orth=6.73e+00 | OffDiag=1.62e-02\n",
      "  MeanRelErr=16503005.2106% | MedianRelErr=99.9324%\n",
      "  λ∈[0.000828, 0.049812] | Spread=0.048984\n",
      "\n",
      "[Stage2] Epoch  94000 | LR=0.000634\n",
      "  Loss=229.468610 | λ₁=5.43e-07 | Trace=0.202\n",
      "  Orth=6.72e+00 | OffDiag=7.75e-03\n",
      "  MeanRelErr=14691230.3131% | MedianRelErr=99.9582%\n",
      "  λ∈[0.000737, 0.062050] | Spread=0.061313\n",
      "\n",
      "[Stage2] Epoch  96000 | LR=0.000606\n",
      "  Loss=229.603023 | λ₁=6.66e-07 | Trace=0.196\n",
      "  Orth=6.72e+00 | OffDiag=7.49e-03\n",
      "  MeanRelErr=16271836.0573% | MedianRelErr=99.9616%\n",
      "  λ∈[0.000816, 0.063423] | Spread=0.062606\n",
      "\n",
      "[Stage2] Epoch  98000 | LR=0.000578\n",
      "  Loss=229.588513 | λ₁=6.17e-07 | Trace=0.195\n",
      "  Orth=6.72e+00 | OffDiag=7.66e-03\n",
      "  MeanRelErr=15686694.2470% | MedianRelErr=99.9606%\n",
      "  λ∈[0.000787, 0.062563] | Spread=0.061776\n",
      "\n",
      "[Stage2] Epoch 100000 | LR=0.000550\n",
      "  Loss=229.471827 | λ₁=7.33e-07 | Trace=0.197\n",
      "  Orth=6.72e+00 | OffDiag=7.45e-03\n",
      "  MeanRelErr=17118220.5032% | MedianRelErr=99.9568%\n",
      "  λ∈[0.000859, 0.064680] | Spread=0.063821\n",
      "  First 5 - Pred: [0.000859 0.000873 0.000874 0.000875 0.000878]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.010772 0.012694 0.012732 0.021011 0.06468 ]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "[Stage2] Epoch 102000 | LR=0.000522\n",
      "  Loss=229.842410 | λ₁=7.30e-07 | Trace=0.195\n",
      "  Orth=6.72e+00 | OffDiag=7.82e-03\n",
      "  MeanRelErr=17037825.1911% | MedianRelErr=99.9588%\n",
      "  λ∈[0.000855, 0.061888] | Spread=0.061033\n",
      "\n",
      "[Stage2] Epoch 104000 | LR=0.000494\n",
      "  Loss=230.797549 | λ₁=7.16e-07 | Trace=0.194\n",
      "  Orth=6.72e+00 | OffDiag=7.78e-03\n",
      "  MeanRelErr=16885775.2337% | MedianRelErr=99.9577%\n",
      "  λ∈[0.000847, 0.061432] | Spread=0.060585\n",
      "\n",
      "[Stage2] Epoch 106000 | LR=0.000466\n",
      "  Loss=229.444988 | λ₁=7.01e-07 | Trace=0.200\n",
      "  Orth=6.72e+00 | OffDiag=7.55e-03\n",
      "  MeanRelErr=16732056.9757% | MedianRelErr=99.9553%\n",
      "  λ∈[0.000840, 0.064054] | Spread=0.063214\n",
      "\n",
      "[Stage2] Epoch 108000 | LR=0.000438\n",
      "  Loss=229.269376 | λ₁=7.22e-07 | Trace=0.215\n",
      "  Orth=6.72e+00 | OffDiag=8.67e-03\n",
      "  MeanRelErr=16957693.1867% | MedianRelErr=99.9598%\n",
      "  λ∈[0.000851, 0.072791] | Spread=0.071940\n",
      "\n",
      "[Stage2] Epoch 110000 | LR=0.000411\n",
      "  Loss=229.578153 | λ₁=6.35e-07 | Trace=0.194\n",
      "  Orth=6.72e+00 | OffDiag=7.20e-03\n",
      "  MeanRelErr=15859768.1985% | MedianRelErr=99.9571%\n",
      "  λ∈[0.000796, 0.062802] | Spread=0.062007\n",
      "  First 5 - Pred: [0.000796 0.000796 0.000798 0.000799 0.000803]\n",
      "  First 5 - True: [0.       0.007574 0.030308 0.068146 0.121208]\n",
      "  Last  5 - Pred: [0.009807 0.012072 0.012079 0.021024 0.062802]\n",
      "  Last  5 - True: [7.607393 7.614276 7.708104 7.724856 7.834566]\n",
      "\n",
      "\n",
      "⚠ Early stopping at epoch 110000 (no improvement for 50000 epochs)\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Loading best model for evaluation...\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      " Orthogonality Quality:\n",
      "  ||U^T M U - I||_F = 8.03e+01\n",
      "  Diagonal range: [1.748742, 33.932425] (target: 1.0)\n",
      "\n",
      " Rayleigh Quotient Matrix:\n",
      "  Diagonal norm: 54.303540\n",
      "  Off-diagonal norm: 5.46e+01 (should be ≈0)\n",
      "\n",
      " Eigenvalue Comparison (First 10):\n",
      "Mode   Predicted      Reference      Abs Error      Rel Error   \n",
      "----------------------------------------------------------------------\n",
      "1      3.65955939     0.00000000     3.65955939     3646784379483.6436%\n",
      "2      4.81319606     0.00757414     4.80562192     63447.7187% \n",
      "3      5.22718049     0.03030791     5.19687257     17146.9167% \n",
      "4      5.69575640     0.06814648     5.62760992     8258.1079%  \n",
      "5      5.73328748     0.12120797     5.61207952     4630.1243%  \n",
      "6      5.79859149     0.18924275     5.60934874     2964.1023%  \n",
      "7      5.89083990     0.27223150     5.61860840     2063.9083%  \n",
      "8      5.90872038     0.37053595     5.53818443     1494.6416%  \n",
      "9      5.93758666     0.48340942     5.45417724     1128.2729%  \n",
      "10     5.94177653     0.61134254     5.33043398     871.9226%   \n",
      "\n",
      " Eigenvalue Comparison (Last 10):\n",
      "Mode   Predicted      Reference      Abs Error      Rel Error   \n",
      "----------------------------------------------------------------------\n",
      "41     8.74165905     7.42219306     1.31946599     17.7773%    \n",
      "42     8.77127296     7.44948415     1.32178881     17.7434%    \n",
      "43     8.80148708     7.45560059     1.34588649     18.0520%    \n",
      "44     8.92210428     7.50810380     1.41400048     18.8330%    \n",
      "45     9.02426435     7.52679082     1.49747354     19.8952%    \n",
      "46     9.35026445     7.60739344     1.74287100     22.9102%    \n",
      "47     9.60735507     7.61427628     1.99307879     26.1756%    \n",
      "48     9.84843433     7.70810371     2.14033062     27.7673%    \n",
      "49     11.15711635    7.72485585     3.43226050     44.4314%    \n",
      "50     13.88468334    7.83456560     6.05011774     77.2234%    \n",
      "\n",
      " Overall Statistics (50 modes):\n",
      "  Mean Absolute Error:     3.26439884\n",
      "  Mean Relative Error:     72935689724.4361%\n",
      "  Median Relative Error:   73.3399%\n",
      "  Max Relative Error:      3646784379483.6436%\n",
      "  Modes with <1% error:    0/50\n",
      "  Modes with <5% error:    0/50\n",
      "  Modes with <10% error:   0/50\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✓ Model saved to 'final_model.pt'\n",
      "✓ Checkpoints saved to 'checkpoints/' directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'k': 50,  # Number of eigenmodes\n",
    "    'max_epochs': 150_000,  # Reduced from 300k due to better architecture\n",
    "    'stage1_epochs': 50_000,  # Focus on low modes + orthogonality\n",
    "    'stage2_epochs': 100_000,  # Fine-tune all modes\n",
    "    'lr_stage1': 0.01,\n",
    "    'lr_stage2': 0.001,\n",
    "    'lr_min': 0.0001,\n",
    "    'print_every': 2000,\n",
    "    'checkpoint_every': 5000,\n",
    "    'grad_clip': 1.0,\n",
    "    'accumulation_steps': 1,  # Set to 4 if you have memory issues\n",
    "    'early_stopping_patience': 50_000,\n",
    "    'early_stopping_threshold': 0.999,  # 0.1% improvement needed\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading mesh...\")\n",
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "# Normalize vertices\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "verts_new = (m.verts - centroid) / std_max\n",
    "m = Mesh(verts=verts_new, connectivity=m.connectivity)\n",
    "\n",
    "print('Computing Laplacian...')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "print('Computing eigenvalues (reference)...')\n",
    "eigvals, eigvecs = linalg.eigh(K, M)\n",
    "\n",
    "# Convert to torch tensors\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)\n",
    "eigvals_torch = torch.from_numpy(eigvals[:CONFIG['k']]).to(device)\n",
    "eigvecs_torch = torch.from_numpy(eigvecs[:, :CONFIG['k']]).to(device)\n",
    "\n",
    "k = CONFIG['k']\n",
    "N = X.shape[0]\n",
    "\n",
    "# ============================================================================\n",
    "# MATRIX CONDITIONING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== Matrix Conditioning ===\")\n",
    "epsilon = 1e-4\n",
    "K_reg = K + epsilon * torch.eye(N, device=device)\n",
    "K_scale = torch.norm(K_reg, p='fro')\n",
    "\n",
    "# Normalize both matrices by same scale\n",
    "K = K_reg / K_scale\n",
    "M = M / K_scale\n",
    "\n",
    "print(f\"Regularization: ε={epsilon}\")\n",
    "print(f\"Condition number: {torch.linalg.cond(K).item():.2e}\")\n",
    "print(f\"Scaling factor: {K_scale:.2e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "class ImprovedMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced MLP with:\n",
    "    - Fourier feature encoding\n",
    "    - Layer normalization\n",
    "    - Residual connections\n",
    "    - Increased capacity\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=3, out_dim=50, hidden=[256, 256, 128, 128], \n",
    "                 use_fourier=True, n_fourier_features=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_fourier = use_fourier\n",
    "        self.n_fourier = n_fourier_features\n",
    "        \n",
    "        # Learnable frequency scales for Fourier features\n",
    "        if use_fourier:\n",
    "            self.freq_scale = nn.Parameter(torch.ones(in_dim) * 10.0)\n",
    "            input_dim = in_dim * (1 + 2 * n_fourier_features)  # original + sin + cos for each freq\n",
    "        else:\n",
    "            input_dim = in_dim\n",
    "        \n",
    "        # Build network with normalization and residual capability\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        \n",
    "        last_dim = input_dim\n",
    "        for h in hidden:\n",
    "            self.layers.append(nn.Linear(last_dim, h))\n",
    "            self.norms.append(nn.LayerNorm(h))\n",
    "            last_dim = h\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(last_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Fourier feature mapping\n",
    "        if self.use_fourier:\n",
    "            features = [x]\n",
    "            for i in range(self.n_fourier):\n",
    "                freq = self.freq_scale * (2 ** i)  # Multiple frequency scales\n",
    "                features.append(torch.sin(freq * x))\n",
    "                features.append(torch.cos(freq * x))\n",
    "            h = torch.cat(features, dim=-1)\n",
    "        else:\n",
    "            h = x\n",
    "        \n",
    "        # Forward pass with residual connections\n",
    "        for i, (layer, norm) in enumerate(zip(self.layers, self.norms)):\n",
    "            h_new = layer(h)\n",
    "            h_new = norm(h_new)\n",
    "            h_new = torch.nn.functional.silu(h_new)\n",
    "            \n",
    "            # Residual connection (if dimensions match)\n",
    "            if i > 0 and h.shape[-1] == h_new.shape[-1]:\n",
    "                h = h_new + 0.1 * h  # Scaled residual\n",
    "            else:\n",
    "                h = h_new\n",
    "        \n",
    "        return self.output(h)\n",
    "\n",
    "# ============================================================================\n",
    "# ORTHOGONALIZATION UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def gram_schmidt_batch(U, M, num_steps=1):\n",
    "    \"\"\"\n",
    "    M-orthogonalize columns of U using Gram-Schmidt process\n",
    "    \n",
    "    Args:\n",
    "        U: (N, k) matrix to orthogonalize\n",
    "        M: (N, N) mass matrix\n",
    "        num_steps: number of GS iterations (>1 for stability)\n",
    "    \"\"\"\n",
    "    Q = U.clone()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        for i in range(Q.shape[1]):\n",
    "            # Orthogonalize against all previous vectors\n",
    "            for j in range(i):\n",
    "                # M-inner product\n",
    "                numerator = Q[:, j] @ (M @ Q[:, i])\n",
    "                denominator = Q[:, j] @ (M @ Q[:, j]) + 1e-10\n",
    "                proj = numerator / denominator\n",
    "                Q[:, i] = Q[:, i] - proj * Q[:, j]\n",
    "            \n",
    "            # M-normalize\n",
    "            norm = torch.sqrt(Q[:, i] @ (M @ Q[:, i]) + 1e-10)\n",
    "            Q[:, i] = Q[:, i] / norm\n",
    "    \n",
    "    return Q\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS COMPUTATION\n",
    "# ============================================================================\n",
    "\n",
    "def compute_loss(U, K, M, eigvals_ref, epoch, config):\n",
    "    \"\"\"\n",
    "    Comprehensive loss function with multiple objectives\n",
    "    UNSUPERVISED: eigvals_ref only used for logging/comparison, NOT for training!\n",
    "    \"\"\"\n",
    "    # Compute Rayleigh quotients\n",
    "    UMU = U.T @ (M @ U)\n",
    "    UKU = U.T @ (K @ U)\n",
    "    \n",
    "    # Extract diagonal (eigenvalue estimates)\n",
    "    eigenvalues_approx = torch.diag(UKU)\n",
    "    sorted_eigs, sort_idx = torch.sort(eigenvalues_approx)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. EIGENVALUE LOSSES (UNSUPERVISED)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # 1a. First eigenvalue should be ZERO (rigid body mode)\n",
    "    #     This is a physical constraint for Laplacian operators\n",
    "    zero_eig_loss = sorted_eigs[0] ** 2\n",
    "    \n",
    "    # 1b. Trace loss (minimize sum - finds smallest modes)\n",
    "    #     But exclude first mode since we're already constraining it to zero\n",
    "    trace_loss = torch.sum(sorted_eigs[1:])\n",
    "    \n",
    "    # 1c. Diversity loss (encourage eigenvalue separation)\n",
    "    # Use adaptive gaps based on current eigenvalue scale\n",
    "    gaps = sorted_eigs[1:] - sorted_eigs[:-1]\n",
    "    # Target minimum gap: 1% of current eigenvalue spread\n",
    "    current_spread = sorted_eigs[-1] - sorted_eigs[1] + 1e-8  # Exclude first eigenvalue\n",
    "    min_gap = current_spread * 0.01 / k  # Adaptive to current scale\n",
    "    diversity_loss = torch.sum(torch.relu(min_gap - gaps))\n",
    "    \n",
    "    # 1d. Off-diagonal penalty (enforce diagonalization)\n",
    "    off_diag_mask = 1 - torch.eye(k, device=device, dtype=torch.float64)\n",
    "    off_diag_loss = torch.sum((UKU * off_diag_mask) ** 2)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. ORTHOGONALITY LOSS\n",
    "    # ========================================================================\n",
    "    \n",
    "    identity_k = torch.eye(k, device=device, dtype=torch.float64)\n",
    "    orth_loss = torch.norm(UMU - identity_k, p='fro') ** 2\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. ORDERING LOSS (maintain λ₁ ≤ λ₂ ≤ ... ≤ λₖ)\n",
    "    # ========================================================================\n",
    "    \n",
    "    ordering_loss = torch.sum(torch.relu(sorted_eigs[:-1] - sorted_eigs[1:])) / k\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. SMOOTHNESS REGULARIZATION (optional, for later stages)\n",
    "    # ========================================================================\n",
    "    \n",
    "    if epoch > config['stage1_epochs']:\n",
    "        U_sorted = U[:, sort_idx]\n",
    "        # Penalize large jumps between consecutive modes\n",
    "        smoothness_loss = torch.mean(torch.sum((U_sorted[:, 1:] - U_sorted[:, :-1]) ** 2, dim=0))\n",
    "    else:\n",
    "        smoothness_loss = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ADAPTIVE WEIGHTING (FULLY UNSUPERVISED)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Stage 1: Focus on orthogonality and finding low modes\n",
    "    if epoch <= config['stage1_epochs']:\n",
    "        w_zero = 100.0       # CRITICAL: Force first eigenvalue to zero\n",
    "        w_trace = 5.0        # Strong push to find smallest eigenvalues\n",
    "        w_div = 2.0          # Encourage separation\n",
    "        w_offdiag = 10.0     # Strong diagonalization\n",
    "        w_orth = 10.0        # Strong orthogonality\n",
    "        w_order = 0.5        # Maintain ordering\n",
    "        w_smooth = 0.0\n",
    "    # Stage 2: Fine-tune, relax some constraints\n",
    "    else:\n",
    "        w_zero = 50.0        # Still enforce, but can relax a bit\n",
    "        w_trace = 2.0        # Still minimize, but less aggressive\n",
    "        w_div = 1.0          # Maintain separation\n",
    "        w_offdiag = 15.0     # Even stronger diagonalization\n",
    "        w_orth = 5.0         # Maintain orthogonality\n",
    "        w_order = 0.2        # Maintain ordering\n",
    "        w_smooth = 0.1       # Add smoothness\n",
    "    \n",
    "    # Total loss (NO SUPERVISION)\n",
    "    total_loss = (w_zero * zero_eig_loss +\n",
    "                  w_trace * trace_loss +\n",
    "                  w_div * diversity_loss +\n",
    "                  w_offdiag * off_diag_loss +\n",
    "                  w_orth * orth_loss +\n",
    "                  w_order * ordering_loss +\n",
    "                  w_smooth * smoothness_loss)\n",
    "    \n",
    "    # Return loss and components for logging\n",
    "    components = {\n",
    "        'zero_eig': zero_eig_loss.item(),\n",
    "        'trace': trace_loss.item(),\n",
    "        'diversity': diversity_loss.item(),\n",
    "        'offdiag': off_diag_loss.item(),\n",
    "        'orth': orth_loss.item(),\n",
    "        'order': ordering_loss.item(),\n",
    "        'smooth': smoothness_loss.item(),\n",
    "    }\n",
    "    \n",
    "    return total_loss, components\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== Initializing Model ===\")\n",
    "model = ImprovedMLP(in_dim=3, out_dim=k, use_fourier=True).double().to(device)\n",
    "\n",
    "# Xavier initialization for hidden layers, small weights for output\n",
    "for name, p in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        if 'output' in name:\n",
    "            nn.init.normal_(p.data, std=1e-4)\n",
    "        elif 'freq_scale' not in name and p.ndim >= 2:  # Only for 2D+ tensors\n",
    "            nn.init.xavier_uniform_(p.data)\n",
    "    elif 'bias' in name:\n",
    "        nn.init.zeros_(p.data)\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Fourier features: {model.use_fourier}\")\n",
    "print(f\"Architecture: {[l.out_features for l in model.layers]} -> {k}\")\n",
    "\n",
    "# ============================================================================\n",
    "# NO PRE-TRAINING - Pure unsupervised learning!\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== Unsupervised Mode: No pre-training ===\")\n",
    "print(\"Model will discover eigenmodes from scratch using only K and M matrices\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Stage 1: High learning rate, focus on orthogonality\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr=CONFIG['lr_stage1'], \n",
    "                        weight_decay=1e-5)\n",
    "\n",
    "# Cosine annealing with restarts\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=10000, T_mult=2, eta_min=CONFIG['lr_min']\n",
    ")\n",
    "\n",
    "# Tracking\n",
    "loss_history = []\n",
    "best_loss = float('inf')\n",
    "no_improve_count = 0\n",
    "checkpoint_dir = Path('checkpoints')\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING START\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Epochs: {CONFIG['max_epochs']:,} | Device: {device}\")\n",
    "print(f\"Stage 1: 0-{CONFIG['stage1_epochs']:,} (orthogonality focus)\")\n",
    "print(f\"Stage 2: {CONFIG['stage1_epochs']:,}-{CONFIG['max_epochs']:,} (eigenvalue tuning)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for epoch in range(1, CONFIG['max_epochs'] + 1):\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE TRANSITION\n",
    "    # ========================================================================\n",
    "    \n",
    "    if epoch == CONFIG['stage1_epochs'] + 1:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ENTERING STAGE 2: Fine-tuning eigenvalues\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        # Reduce learning rate for stage 2\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = CONFIG['lr_stage2']\n",
    "        \n",
    "        # Reset scheduler for stage 2\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, \n",
    "            T_max=CONFIG['stage2_epochs'],\n",
    "            eta_min=CONFIG['lr_min']\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TRAINING STEP\n",
    "    # ========================================================================\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    U = model(X)\n",
    "    \n",
    "    # Periodic explicit orthogonalization (every 1000 steps in stage 1)\n",
    "    if epoch <= CONFIG['stage1_epochs'] and epoch % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            U = gram_schmidt_batch(U, M, num_steps=2)\n",
    "        \n",
    "        # Quick fine-tune to match orthogonalized output\n",
    "        for _ in range(5):\n",
    "            optimizer.zero_grad()\n",
    "            U_pred = model(X)\n",
    "            loss_proj = torch.mean((U_pred - U) ** 2)\n",
    "            loss_proj.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['grad_clip'])\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Compute loss\n",
    "    optimizer.zero_grad()\n",
    "    U = model(X)\n",
    "    loss, loss_components = compute_loss(U, K, M, eigvals_torch, epoch, CONFIG)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['grad_clip'])\n",
    "    \n",
    "    # Optimizer step (with optional gradient accumulation)\n",
    "    if epoch % CONFIG['accumulation_steps'] == 0:\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOGGING\n",
    "    # ========================================================================\n",
    "    \n",
    "    if epoch % CONFIG['print_every'] == 0 or epoch == 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            U = model(X)\n",
    "            UKU = U.T @ (K @ U)\n",
    "            UMU = U.T @ (M @ U)\n",
    "            \n",
    "            approx_eigs = torch.diag(UKU).cpu().numpy()\n",
    "            approx_eigs.sort()\n",
    "            \n",
    "            # Compute errors\n",
    "            abs_error = np.abs(approx_eigs - eigvals[:k])\n",
    "            rel_error = abs_error / (np.abs(eigvals[:k]) + 1e-10)\n",
    "            mean_rel_error = np.mean(rel_error)\n",
    "            median_rel_error = np.median(rel_error)\n",
    "            \n",
    "            # Orthogonality check\n",
    "            orth_residual = torch.norm(UMU - torch.eye(k, device=device, dtype=torch.float64), p='fro').item()\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            stage = \"Stage1\" if epoch <= CONFIG['stage1_epochs'] else \"Stage2\"\n",
    "            \n",
    "        print(f\"[{stage}] Epoch {epoch:>6} | LR={current_lr:.6f}\")\n",
    "        print(f\"  Loss={loss.item():.6f} | λ₁={loss_components['zero_eig']:.2e} | Trace={loss_components['trace']:.3f}\")\n",
    "        print(f\"  Orth={orth_residual:.2e} | OffDiag={loss_components['offdiag']:.2e}\")\n",
    "        print(f\"  MeanRelErr={mean_rel_error:.4%} | MedianRelErr={median_rel_error:.4%}\")\n",
    "        print(f\"  λ∈[{approx_eigs[0]:.6f}, {approx_eigs[-1]:.6f}] | Spread={approx_eigs[-1]-approx_eigs[0]:.6f}\")\n",
    "        \n",
    "        # Detailed comparison every 10k epochs\n",
    "        if epoch % (CONFIG['print_every'] * 5) == 0:\n",
    "            print(f\"  First 5 - Pred: {approx_eigs[:5].round(6)}\")\n",
    "            print(f\"  First 5 - True: {eigvals[:5].round(6)}\")\n",
    "            print(f\"  Last  5 - Pred: {approx_eigs[-5:].round(6)}\")\n",
    "            print(f\"  Last  5 - True: {eigvals[k-5:k].round(6)}\")\n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CHECKPOINTING & EARLY STOPPING\n",
    "    # ========================================================================\n",
    "    \n",
    "    if epoch % CONFIG['checkpoint_every'] == 0:\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'loss_history': loss_history,\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_dir / f'checkpoint_epoch_{epoch}.pt')\n",
    "        \n",
    "        # Check for improvement\n",
    "        if loss.item() < best_loss * CONFIG['early_stopping_threshold']:\n",
    "            best_loss = loss.item()\n",
    "            no_improve_count = 0\n",
    "            torch.save(checkpoint, checkpoint_dir / 'best_model.pt')\n",
    "            print(f\"  ✓ New best model saved (loss={best_loss:.6f})\")\n",
    "        else:\n",
    "            no_improve_count += CONFIG['checkpoint_every']\n",
    "        \n",
    "        # Early stopping\n",
    "        if no_improve_count >= CONFIG['early_stopping_patience']:\n",
    "            print(f\"\\n⚠ Early stopping at epoch {epoch} (no improvement for {no_improve_count} epochs)\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading best model for evaluation...\")\n",
    "best_checkpoint = torch.load(checkpoint_dir / 'best_model.pt')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    U = model(X)\n",
    "    \n",
    "    # Final matrices\n",
    "    final_UKU = U.T @ (K @ U)\n",
    "    final_UMU = U.T @ (M @ U)\n",
    "    \n",
    "    # Eigenvalues\n",
    "    final_eigs = torch.diag(final_UKU).cpu().numpy()\n",
    "    final_eigs.sort()\n",
    "    \n",
    "    # Errors\n",
    "    abs_error = np.abs(final_eigs - eigvals[:k])\n",
    "    rel_error = abs_error / (np.abs(eigvals[:k]) + 1e-10)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Orthogonality\n",
    "    identity_k = torch.eye(k, device=device, dtype=torch.float64)\n",
    "    orth_residual = torch.norm(final_UMU - identity_k, p='fro').item()\n",
    "    orth_diag = torch.diag(final_UMU).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\n Orthogonality Quality:\")\n",
    "    print(f\"  ||U^T M U - I||_F = {orth_residual:.2e}\")\n",
    "    print(f\"  Diagonal range: [{orth_diag.min():.6f}, {orth_diag.max():.6f}] (target: 1.0)\")\n",
    "    \n",
    "    # Rayleigh matrix\n",
    "    rayleigh_diag = torch.diag(final_UKU).cpu().numpy()\n",
    "    rayleigh_offdiag = (final_UKU - torch.diag(torch.diag(final_UKU))).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\n Rayleigh Quotient Matrix:\")\n",
    "    print(f\"  Diagonal norm: {np.linalg.norm(rayleigh_diag):.6f}\")\n",
    "    print(f\"  Off-diagonal norm: {np.linalg.norm(rayleigh_offdiag, 'fro'):.2e} (should be ≈0)\")\n",
    "    \n",
    "    # Eigenvalue comparison\n",
    "    print(f\"\\n Eigenvalue Comparison (First 10):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<14} {'Reference':<14} {'Abs Error':<14} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(min(10, k)):\n",
    "        print(f\"{i+1:<6} {final_eigs[i]:<14.8f} {eigvals[i]:<14.8f} \"\n",
    "              f\"{abs_error[i]:<14.8f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    print(f\"\\n Eigenvalue Comparison (Last 10):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<14} {'Reference':<14} {'Abs Error':<14} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(max(0, k-10), k):\n",
    "        print(f\"{i+1:<6} {final_eigs[i]:<14.8f} {eigvals[i]:<14.8f} \"\n",
    "              f\"{abs_error[i]:<14.8f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\n Overall Statistics ({k} modes):\")\n",
    "    print(f\"  Mean Absolute Error:     {np.mean(abs_error):.8f}\")\n",
    "    print(f\"  Mean Relative Error:     {np.mean(rel_error):.4%}\")\n",
    "    print(f\"  Median Relative Error:   {np.median(rel_error):.4%}\")\n",
    "    print(f\"  Max Relative Error:      {np.max(rel_error):.4%}\")\n",
    "    print(f\"  Modes with <1% error:    {np.sum(rel_error < 0.01)}/{k}\")\n",
    "    print(f\"  Modes with <5% error:    {np.sum(rel_error < 0.05)}/{k}\")\n",
    "    print(f\"  Modes with <10% error:   {np.sum(rel_error < 0.10)}/{k}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'final_eigenvalues': final_eigs,\n",
    "    'reference_eigenvalues': eigvals[:k],\n",
    "    'errors': {'absolute': abs_error, 'relative': rel_error},\n",
    "}, 'final_model.pt')\n",
    "\n",
    "print(\"\\n✓ Model saved to 'final_model.pt'\")\n",
    "print(\"✓ Checkpoints saved to 'checkpoints/' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc212e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12344bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a096a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c5789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a3675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a98172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406bab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
