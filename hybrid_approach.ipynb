{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51e97eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh...\n",
      "Computing Laplacian...\n",
      "Computing reference eigenvalues...\n",
      "\n",
      "=== Matrix Diagnostics ===\n",
      "N = 1546, k = 50, ratio = 30.9\n",
      "Condition number of K: 2.56e+16\n",
      "Condition number of M: 3.70e+02\n",
      "Target eigenvalue range: [0.000000, 7.834566]\n",
      "⚠ Large eigenvalue spread detected\n",
      "\n",
      "Regularization: ε=0.0001\n",
      "Condition number after reg: 1.47e+05\n",
      "\n",
      "Normalization:\n",
      "  K_scale = 1.58e+02\n",
      "  M_scale = 1.22e+00\n",
      "  ||K||_F = 1.0000\n",
      "  ||M||_F = 1.0000\n",
      "\n",
      "Sanity checks:\n",
      "  K symmetric: True\n",
      "  M positive definite: True\n",
      "  No NaN/Inf: True\n",
      "\n",
      "================================================================================\n",
      "=== Initializing Model ===\n",
      "Parameters: 128,821\n",
      "Architecture: [256, 256, 128, 128] -> 50\n",
      "Fourier features: Enabled (3 frequencies)\n",
      "\n",
      "================================================================================\n",
      "HYBRID TRAINING START\n",
      "================================================================================\n",
      "Strategy: SVD orthogonalization + Fourier features + Two-stage training\n",
      "Stage 1: 0-50,000 | Stage 2: 50,000-150,000\n",
      "================================================================================\n",
      "\n",
      "[Stage1] Epoch      1 | LR=0.010000\n",
      "  Loss=54.752092 | λ₁²=5.06e-01 | Trace=0.820\n",
      "  Orth=1.71e-13 | OffDiag=2.02e-03 | SVD_cond=1.80e+03\n",
      "  MeanRelErr=1840041252546.8276% | MedianRelErr=2295.1240%\n",
      "  λ∈[92.324352, 121.184859]\n",
      "\n",
      "[Stage1] Epoch   2000 | LR=0.009055\n",
      "  Loss=0.168698 | λ₁²=4.96e-07 | Trace=0.034\n",
      "  Orth=1.79e-13 | OffDiag=1.04e-05 | SVD_cond=8.08e+02\n",
      "  MeanRelErr=1822748450.8992% | MedianRelErr=37.2801%\n",
      "  λ∈[0.091457, 5.430113]\n",
      "\n",
      "[Stage1] Epoch   4000 | LR=0.006580\n",
      "  Loss=0.166620 | λ₁²=2.75e-07 | Trace=0.033\n",
      "  Orth=1.59e-13 | OffDiag=9.94e-06 | SVD_cond=7.65e+02\n",
      "  MeanRelErr=1356155641.1657% | MedianRelErr=36.3281%\n",
      "  λ∈[0.068045, 5.774048]\n",
      "\n",
      "  ✓ New best model (loss=0.166413)\n",
      "[Stage1] Epoch   6000 | LR=0.003520\n",
      "  Loss=0.166329 | λ₁²=2.69e-07 | Trace=0.033\n",
      "  Orth=1.77e-13 | OffDiag=9.77e-06 | SVD_cond=7.88e+02\n",
      "  MeanRelErr=1342597780.7430% | MedianRelErr=34.6041%\n",
      "  λ∈[0.067365, 5.850149]\n",
      "\n",
      "[Stage1] Epoch   8000 | LR=0.001045\n",
      "  Loss=0.166249 | λ₁²=2.60e-07 | Trace=0.033\n",
      "  Orth=1.93e-13 | OffDiag=9.52e-06 | SVD_cond=9.97e+02\n",
      "  MeanRelErr=1319696313.7245% | MedianRelErr=33.1246%\n",
      "  λ∈[0.066216, 6.024561]\n",
      "\n",
      "[Stage1] Epoch  10000 | LR=0.010000\n",
      "  Loss=0.166248 | λ₁²=2.59e-07 | Trace=0.033\n",
      "  Orth=1.68e-13 | OffDiag=9.47e-06 | SVD_cond=6.14e+02\n",
      "  MeanRelErr=1316904194.9573% | MedianRelErr=33.3072%\n",
      "  λ∈[0.066076, 6.051206]\n",
      "  First 5 - Pred: [0.06607581 2.73499928 2.75397536 2.84236037 2.86814458]\n",
      "  First 5 - True: [3.50308915e-13 7.57414444e-03 3.03079128e-02 6.81464805e-02\n",
      " 1.21207968e-01]\n",
      "  Last  5 - Pred: [5.61407377 5.63152513 5.6438054  5.91950069 6.05120578]\n",
      "  Last  5 - True: [7.60739344 7.61427628 7.70810371 7.72485585 7.8345656 ]\n",
      "\n",
      "[Stage1] Epoch  12000 | LR=0.009758\n",
      "  Loss=0.166428 | λ₁²=3.21e-07 | Trace=0.033\n",
      "  Orth=1.96e-13 | OffDiag=9.78e-06 | SVD_cond=7.67e+02\n",
      "  MeanRelErr=1466751559.4457% | MedianRelErr=35.2228%\n",
      "  λ∈[0.073594, 5.630254]\n",
      "\n",
      "[Stage1] Epoch  14000 | LR=0.009055\n",
      "  Loss=0.166386 | λ₁²=2.93e-07 | Trace=0.033\n",
      "  Orth=1.75e-13 | OffDiag=9.44e-06 | SVD_cond=6.83e+02\n",
      "  MeanRelErr=1400080375.7507% | MedianRelErr=34.6468%\n",
      "  λ∈[0.070249, 6.038780]\n",
      "\n",
      "[Stage1] Epoch  16000 | LR=0.007960\n",
      "  Loss=0.166286 | λ₁²=3.07e-07 | Trace=0.033\n",
      "  Orth=1.84e-13 | OffDiag=9.28e-06 | SVD_cond=8.41e+02\n",
      "  MeanRelErr=1433647591.1699% | MedianRelErr=33.1357%\n",
      "  λ∈[0.071933, 6.397848]\n",
      "\n",
      "[Stage1] Epoch  18000 | LR=0.006580\n",
      "  Loss=0.166261 | λ₁²=2.63e-07 | Trace=0.033\n",
      "  Orth=1.67e-13 | OffDiag=9.01e-06 | SVD_cond=7.50e+02\n",
      "  MeanRelErr=1327367048.5322% | MedianRelErr=32.9154%\n",
      "  λ∈[0.066601, 6.243773]\n",
      "\n",
      "[Stage1] Epoch  20000 | LR=0.005050\n",
      "  Loss=0.166324 | λ₁²=2.93e-07 | Trace=0.033\n",
      "  Orth=1.75e-13 | OffDiag=8.63e-06 | SVD_cond=7.55e+02\n",
      "  MeanRelErr=1400412713.5062% | MedianRelErr=29.6309%\n",
      "  λ∈[0.070266, 6.298286]\n",
      "  First 5 - Pred: [0.07026589 1.43976261 2.05502977 2.32903191 2.52421166]\n",
      "  First 5 - True: [3.50308915e-13 7.57414444e-03 3.03079128e-02 6.81464805e-02\n",
      " 1.21207968e-01]\n",
      "  Last  5 - Pred: [6.03353493 6.04972703 6.0888756  6.18383492 6.29828567]\n",
      "  Last  5 - True: [7.60739344 7.61427628 7.70810371 7.72485585 7.8345656 ]\n",
      "\n",
      "[Stage1] Epoch  22000 | LR=0.003520\n",
      "  Loss=0.166291 | λ₁²=2.85e-07 | Trace=0.033\n",
      "  Orth=1.38e-13 | OffDiag=8.45e-06 | SVD_cond=7.32e+02\n",
      "  MeanRelErr=1382632288.3982% | MedianRelErr=29.3454%\n",
      "  λ∈[0.069374, 6.554208]\n",
      "\n",
      "[Stage1] Epoch  24000 | LR=0.002140\n",
      "  Loss=0.166181 | λ₁²=2.59e-07 | Trace=0.033\n",
      "  Orth=1.64e-13 | OffDiag=7.51e-06 | SVD_cond=9.43e+02\n",
      "  MeanRelErr=1318001439.0826% | MedianRelErr=25.7756%\n",
      "  λ∈[0.066131, 6.677771]\n",
      "\n",
      "  ✓ New best model (loss=0.166197)\n",
      "[Stage1] Epoch  26000 | LR=0.001045\n",
      "  Loss=0.166178 | λ₁²=2.59e-07 | Trace=0.033\n",
      "  Orth=1.31e-13 | OffDiag=7.17e-06 | SVD_cond=4.70e+02\n",
      "  MeanRelErr=1315885391.4322% | MedianRelErr=25.3564%\n",
      "  λ∈[0.066025, 6.623838]\n",
      "\n",
      "[Stage1] Epoch  28000 | LR=0.000342\n",
      "  Loss=0.166167 | λ₁²=2.60e-07 | Trace=0.033\n",
      "  Orth=1.49e-13 | OffDiag=6.67e-06 | SVD_cond=5.71e+02\n",
      "  MeanRelErr=1320228938.1948% | MedianRelErr=24.2472%\n",
      "  λ∈[0.066243, 6.745641]\n",
      "\n",
      "[Stage1] Epoch  30000 | LR=0.010000\n",
      "  Loss=0.166163 | λ₁²=2.60e-07 | Trace=0.033\n",
      "  Orth=1.36e-13 | OffDiag=6.37e-06 | SVD_cond=6.34e+02\n",
      "  MeanRelErr=1319621963.3083% | MedianRelErr=23.0418%\n",
      "  λ∈[0.066212, 6.814342]\n",
      "  First 5 - Pred: [0.06621222 0.48044246 1.28455745 1.40892977 1.43011578]\n",
      "  First 5 - True: [3.50308915e-13 7.57414444e-03 3.03079128e-02 6.81464805e-02\n",
      " 1.21207968e-01]\n",
      "  Last  5 - Pred: [6.63443334 6.65643215 6.66272816 6.69734811 6.81434155]\n",
      "  Last  5 - True: [7.60739344 7.61427628 7.70810371 7.72485585 7.8345656 ]\n",
      "\n",
      "[Stage1] Epoch  32000 | LR=0.009939\n",
      "  Loss=0.166388 | λ₁²=2.99e-07 | Trace=0.033\n",
      "  Orth=1.53e-13 | OffDiag=7.27e-06 | SVD_cond=7.05e+02\n",
      "  MeanRelErr=1415325898.0868% | MedianRelErr=23.7153%\n",
      "  λ∈[0.071014, 6.567816]\n",
      "\n",
      "[Stage1] Epoch  34000 | LR=0.009758\n",
      "  Loss=0.166182 | λ₁²=2.64e-07 | Trace=0.033\n",
      "  Orth=1.64e-13 | OffDiag=5.92e-06 | SVD_cond=8.64e+02\n",
      "  MeanRelErr=1330290094.6281% | MedianRelErr=20.8195%\n",
      "  λ∈[0.066747, 6.822775]\n",
      "\n",
      "[Stage1] Epoch  36000 | LR=0.009460\n",
      "  Loss=0.166204 | λ₁²=2.68e-07 | Trace=0.033\n",
      "  Orth=1.55e-13 | OffDiag=6.25e-06 | SVD_cond=7.86e+02\n",
      "  MeanRelErr=1340617667.6563% | MedianRelErr=22.8839%\n",
      "  λ∈[0.067266, 6.959795]\n",
      "\n",
      "[Stage1] Epoch  38000 | LR=0.009055\n",
      "  Loss=0.166155 | λ₁²=2.51e-07 | Trace=0.033\n",
      "  Orth=1.72e-13 | OffDiag=4.52e-06 | SVD_cond=9.86e+02\n",
      "  MeanRelErr=1295691936.7264% | MedianRelErr=17.5890%\n",
      "  λ∈[0.065012, 7.136470]\n",
      "\n",
      "[Stage1] Epoch  40000 | LR=0.008550\n",
      "  Loss=0.166186 | λ₁²=2.64e-07 | Trace=0.033\n",
      "  Orth=1.47e-13 | OffDiag=5.66e-06 | SVD_cond=5.36e+02\n",
      "  MeanRelErr=1328734256.3793% | MedianRelErr=19.8096%\n",
      "  λ∈[0.066669, 7.145607]\n",
      "  First 5 - Pred: [0.06666943 0.86685539 1.09519244 1.29557308 1.35986277]\n",
      "  First 5 - True: [3.50308915e-13 7.57414444e-03 3.03079128e-02 6.81464805e-02\n",
      " 1.21207968e-01]\n",
      "  Last  5 - Pred: [6.69625621 6.83570544 6.90814109 6.93315259 7.14560739]\n",
      "  Last  5 - True: [7.60739344 7.61427628 7.70810371 7.72485585 7.8345656 ]\n",
      "\n",
      "[Stage1] Epoch  42000 | LR=0.007960\n",
      "  Loss=0.166140 | λ₁²=2.62e-07 | Trace=0.033\n",
      "  Orth=1.45e-13 | OffDiag=4.04e-06 | SVD_cond=7.18e+02\n",
      "  MeanRelErr=1323709316.0011% | MedianRelErr=13.4205%\n",
      "  λ∈[0.066417, 7.283788]\n",
      "\n",
      "[Stage1] Epoch  44000 | LR=0.007297\n",
      "  Loss=0.166157 | λ₁²=2.72e-07 | Trace=0.033\n",
      "  Orth=1.48e-13 | OffDiag=3.65e-06 | SVD_cond=5.83e+02\n",
      "  MeanRelErr=1350819872.2708% | MedianRelErr=10.5875%\n",
      "  λ∈[0.067778, 7.188271]\n",
      "\n",
      "[Stage1] Epoch  46000 | LR=0.006580\n",
      "  Loss=0.166121 | λ₁²=2.61e-07 | Trace=0.033\n",
      "  Orth=1.37e-13 | OffDiag=2.40e-06 | SVD_cond=9.25e+02\n",
      "  MeanRelErr=1321941556.5261% | MedianRelErr=7.9144%\n",
      "  λ∈[0.066329, 7.320729]\n",
      "\n",
      "[Stage1] Epoch  48000 | LR=0.005824\n",
      "  Loss=0.166121 | λ₁²=2.56e-07 | Trace=0.033\n",
      "  Orth=1.15e-13 | OffDiag=2.50e-06 | SVD_cond=5.95e+02\n",
      "  MeanRelErr=1309582742.7287% | MedianRelErr=6.6017%\n",
      "  λ∈[0.065709, 7.337324]\n",
      "\n",
      "[Stage1] Epoch  50000 | LR=0.005050\n",
      "  Loss=0.166108 | λ₁²=2.60e-07 | Trace=0.033\n",
      "  Orth=1.18e-13 | OffDiag=1.68e-06 | SVD_cond=8.26e+02\n",
      "  MeanRelErr=1319214639.1384% | MedianRelErr=5.7055%\n",
      "  λ∈[0.066192, 7.419062]\n",
      "  First 5 - Pred: [0.06619179 0.4577853  0.50534121 0.64849231 0.67222746]\n",
      "  First 5 - True: [3.50308915e-13 7.57414444e-03 3.03079128e-02 6.81464805e-02\n",
      " 1.21207968e-01]\n",
      "  Last  5 - Pred: [7.25792328 7.28009132 7.31027641 7.36609423 7.41906202]\n",
      "  Last  5 - True: [7.60739344 7.61427628 7.70810371 7.72485585 7.8345656 ]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STAGE 2: Fine-tuning all eigenvalues\n",
      "================================================================================\n",
      "\n",
      "[Stage2] Epoch  52000 | LR=0.000999\n",
      "  Loss=4.038773 | λ₁²=2.09e-05 | Trace=0.077\n",
      "  Orth=1.51e-13 | OffDiag=2.37e-05 | SVD_cond=6.11e+02\n",
      "  MeanRelErr=11834521355.9655% | MedianRelErr=130.6727%\n",
      "  λ∈[0.593799, 12.036022]\n",
      "\n",
      "[Stage2] Epoch  54000 | LR=0.000996\n",
      "  Loss=4.038811 | λ₁²=1.81e-05 | Trace=0.077\n",
      "  Orth=1.45e-13 | OffDiag=2.11e-05 | SVD_cond=6.82e+02\n",
      "  MeanRelErr=11010003282.6162% | MedianRelErr=129.2695%\n",
      "  λ∈[0.552428, 11.792123]\n",
      "\n",
      "\n",
      "⚠ Early stopping at epoch 55000\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Loading best model...\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      " Orthogonality Quality:\n",
      "  ||U^T M U - I||_F = 1.33e-13\n",
      "  Diagonal range: [1.000000, 1.000000]\n",
      "\n",
      " Rayleigh Matrix:\n",
      "  Diagonal norm: 0.247467\n",
      "  Off-diagonal norm: 1.35e-01\n",
      "\n",
      " SVD Stability:\n",
      "  Condition number: 4.03e+02\n",
      "\n",
      " Eigenvalue Comparison (First 10):\n",
      "Mode   Predicted      Reference      Abs Error      Rel Error   \n",
      "----------------------------------------------------------------------\n",
      "1      0.06623902     0.00000000     0.06623902     66007789439.4338%\n",
      "2      0.64576009     0.00757414     0.63818595     8425.8485%  \n",
      "3      1.49937697     0.03030791     1.46906906     4847.1469%  \n",
      "4      1.68218131     0.06814648     1.61403482     2368.4786%  \n",
      "5      1.76171773     0.12120797     1.64050977     1353.4669%  \n",
      "6      1.90794906     0.18924275     1.71870631     908.2019%   \n",
      "7      2.14583632     0.27223150     1.87360482     688.2395%   \n",
      "8      2.19260169     0.37053595     1.82206574     491.7379%   \n",
      "9      2.29439977     0.48340942     1.81099035     374.6287%   \n",
      "10     2.35737944     0.61134254     1.74603689     285.6070%   \n",
      "\n",
      " Eigenvalue Comparison (Last 10):\n",
      "Mode   Predicted      Reference      Abs Error      Rel Error   \n",
      "----------------------------------------------------------------------\n",
      "41     5.78973748     7.42219306     1.63245558     21.9942%    \n",
      "42     5.95051486     7.44948415     1.49896929     20.1218%    \n",
      "43     6.02387226     7.45560059     1.43172833     19.2034%    \n",
      "44     6.11992014     7.50810380     1.38818366     18.4891%    \n",
      "45     6.27583289     7.52679082     1.25095792     16.6201%    \n",
      "46     6.34187267     7.60739344     1.26552077     16.6354%    \n",
      "47     6.36248520     7.61427628     1.25179108     16.4401%    \n",
      "48     6.40154851     7.70810371     1.30655519     16.9504%    \n",
      "49     6.48634745     7.72485585     1.23850840     16.0328%    \n",
      "50     6.56825587     7.83456560     1.26630974     16.1631%    \n",
      "\n",
      " Overall Statistics (50 modes):\n",
      "  Mean Absolute Error:     1.38236399\n",
      "  Mean Relative Error:     1320156220.5102%\n",
      "  Median Relative Error:   26.2029%\n",
      "  Max Relative Error:      66007789439.4338%\n",
      "  Modes with <1% error:    0/50\n",
      "  Modes with <5% error:    2/50\n",
      "  Modes with <10% error:   3/50\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✓ Model saved to 'hybrid_model_final.pt'\n",
      "✓ Checkpoints in 'checkpoints/' directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONFIG = {\n",
    "    'k': 50,\n",
    "    'max_epochs': 150_000,\n",
    "    'stage1_epochs': 50_000,\n",
    "    'lr_stage1': 0.01,\n",
    "    'lr_stage2': 0.001,\n",
    "    'lr_min': 0.0001,\n",
    "    'print_every': 2000,\n",
    "    'checkpoint_every': 5000,\n",
    "    'grad_clip': 1.0,\n",
    "    'early_stopping_patience': 30_000,\n",
    "    'early_stopping_threshold': 0.999,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading mesh...\")\n",
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "# Normalize vertices\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "verts_new = (m.verts - centroid) / std_max\n",
    "m = Mesh(verts=verts_new, connectivity=m.connectivity)\n",
    "\n",
    "print('Computing Laplacian...')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "print('Computing reference eigenvalues...')\n",
    "eigvals, eigvecs = linalg.eigh(K, M)\n",
    "\n",
    "# Convert to torch\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)\n",
    "\n",
    "k = CONFIG['k']\n",
    "N = X.shape[0]\n",
    "\n",
    "# ============================================================================\n",
    "# MATRIX CONDITIONING (Your careful approach)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== Matrix Diagnostics ===\")\n",
    "print(f\"N = {N}, k = {k}, ratio = {N/k:.1f}\")\n",
    "print(f\"Condition number of K: {torch.linalg.cond(K).item():.2e}\")\n",
    "print(f\"Condition number of M: {torch.linalg.cond(M).item():.2e}\")\n",
    "print(f\"Target eigenvalue range: [{eigvals[0]:.6f}, {eigvals[k-1]:.6f}]\")\n",
    "\n",
    "if eigvals[k-1] / (eigvals[1] + 1e-10) > 100:\n",
    "    print(\"⚠ Large eigenvalue spread detected\")\n",
    "\n",
    "# Regularization\n",
    "epsilon = 1e-4\n",
    "K_reg = K + epsilon * torch.eye(N, device=device)\n",
    "print(f\"\\nRegularization: ε={epsilon}\")\n",
    "print(f\"Condition number after reg: {torch.linalg.cond(K_reg).item():.2e}\")\n",
    "\n",
    "# Separate normalization (your approach - more careful)\n",
    "K_scale = torch.norm(K_reg, p='fro')\n",
    "M_scale = torch.norm(M, p='fro')\n",
    "\n",
    "K = K_reg / K_scale\n",
    "M = M / M_scale\n",
    "\n",
    "print(f\"\\nNormalization:\")\n",
    "print(f\"  K_scale = {K_scale.item():.2e}\")\n",
    "print(f\"  M_scale = {M_scale.item():.2e}\")\n",
    "print(f\"  ||K||_F = {torch.norm(K, p='fro').item():.4f}\")\n",
    "print(f\"  ||M||_F = {torch.norm(M, p='fro').item():.4f}\")\n",
    "\n",
    "# Sanity checks\n",
    "print(f\"\\nSanity checks:\")\n",
    "print(f\"  K symmetric: {torch.allclose(K, K.T, atol=1e-6)}\")\n",
    "print(f\"  M positive definite: {torch.all(torch.linalg.eigvalsh(M) > 0)}\")\n",
    "print(f\"  No NaN/Inf: {not (torch.isnan(K).any() or torch.isinf(K).any())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL DEFINITION (My improved architecture)\n",
    "# ============================================================================\n",
    "\n",
    "class HybridMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines:\n",
    "    - Fourier features for high-frequency modes\n",
    "    - LayerNorm for training stability\n",
    "    - Residual connections for gradient flow\n",
    "    - Wider architecture for capacity\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=3, out_dim=50, hidden=[256, 256, 128, 128],\n",
    "                 use_fourier=True, n_fourier_features=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_fourier = use_fourier\n",
    "        self.n_fourier = n_fourier_features\n",
    "        \n",
    "        # Learnable Fourier frequencies\n",
    "        if use_fourier:\n",
    "            self.freq_scale = nn.Parameter(torch.ones(in_dim) * 10.0)\n",
    "            input_dim = in_dim * (1 + 2 * n_fourier_features)\n",
    "        else:\n",
    "            input_dim = in_dim\n",
    "        \n",
    "        # Network layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        \n",
    "        last_dim = input_dim\n",
    "        for h in hidden:\n",
    "            self.layers.append(nn.Linear(last_dim, h))\n",
    "            self.norms.append(nn.LayerNorm(h))\n",
    "            last_dim = h\n",
    "        \n",
    "        self.output = nn.Linear(last_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Fourier feature mapping\n",
    "        if self.use_fourier:\n",
    "            features = [x]\n",
    "            for i in range(self.n_fourier):\n",
    "                freq = self.freq_scale * (2 ** i)\n",
    "                features.append(torch.sin(freq * x))\n",
    "                features.append(torch.cos(freq * x))\n",
    "            h = torch.cat(features, dim=-1)\n",
    "        else:\n",
    "            h = x\n",
    "        \n",
    "        # Forward with residuals and normalization\n",
    "        for i, (layer, norm) in enumerate(zip(self.layers, self.norms)):\n",
    "            h_new = layer(h)\n",
    "            h_new = norm(h_new)\n",
    "            h_new = torch.nn.functional.silu(h_new)\n",
    "            \n",
    "            # Residual connection (scaled)\n",
    "            if i > 0 and h.shape[-1] == h_new.shape[-1]:\n",
    "                h = h_new + 0.1 * h\n",
    "            else:\n",
    "                h = h_new\n",
    "        \n",
    "        return self.output(h)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=== Initializing Model ===\")\n",
    "model = HybridMLP(in_dim=3, out_dim=k, use_fourier=True).double().to(device)\n",
    "\n",
    "# Careful initialization\n",
    "for name, p in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        if 'output' in name:\n",
    "            nn.init.normal_(p.data, std=1e-4)\n",
    "        elif 'freq_scale' not in name and p.ndim >= 2:\n",
    "            nn.init.xavier_uniform_(p.data)\n",
    "    elif 'bias' in name:\n",
    "        nn.init.zeros_(p.data)\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Architecture: {[l.out_features for l in model.layers]} -> {k}\")\n",
    "print(f\"Fourier features: Enabled ({model.n_fourier} frequencies)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS COMPUTATION (Hybrid approach)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_loss(U, U_orth, K, M, rayleigh_matrix, B, S, eigvals_ref, epoch, config):\n",
    "    \"\"\"\n",
    "    Hybrid loss combining:\n",
    "    - Your SVD stability monitoring\n",
    "    - My zero eigenvalue constraint\n",
    "    - Adaptive weighting for two-stage training\n",
    "    \"\"\"\n",
    "    k = U.shape[1]\n",
    "    identity_k = torch.eye(k, device=device, dtype=torch.float64)\n",
    "    \n",
    "    # Extract eigenvalues\n",
    "    eigenvalues_approx = torch.diag(rayleigh_matrix)\n",
    "    sorted_eigs, sort_idx = torch.sort(eigenvalues_approx)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. ZERO EIGENVALUE CONSTRAINT (Critical for first mode)\n",
    "    # ========================================================================\n",
    "    zero_eig_loss = sorted_eigs[0] ** 2\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. TRACE LOSS (Minimize sum, excluding first eigenvalue)\n",
    "    # ========================================================================\n",
    "    trace_loss = torch.sum(sorted_eigs[1:]) / (k - 1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. DIVERSITY LOSS (Adaptive gap)\n",
    "    # ========================================================================\n",
    "    gaps = sorted_eigs[1:] - sorted_eigs[:-1]\n",
    "    current_spread = sorted_eigs[-1] - sorted_eigs[1] + 1e-8\n",
    "    min_gap = current_spread * 0.005 / k  # 0.5% of spread\n",
    "    diversity_loss = torch.sum(torch.relu(min_gap - gaps)) / (k - 1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. OFF-DIAGONAL PENALTY (Enforce diagonalization)\n",
    "    # ========================================================================\n",
    "    off_diag_mask = 1 - identity_k\n",
    "    off_diag_loss = torch.sum((rayleigh_matrix * off_diag_mask) ** 2) / (k * (k-1))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 5. ORTHOGONALITY RESIDUAL (Should be small due to SVD)\n",
    "    # ========================================================================\n",
    "    B_orth = U_orth.T @ (M @ U_orth)\n",
    "    orth_loss = torch.norm(B_orth - identity_k, p='fro') ** 2\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 6. ORDERING LOSS (Maintain sorted eigenvalues)\n",
    "    # ========================================================================\n",
    "    ordering_loss = torch.sum(torch.relu(sorted_eigs[:-1] - sorted_eigs[1:])) / k\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 7. STABILITY LOSS (Your SVD monitoring)\n",
    "    # ========================================================================\n",
    "    S_ratio = S.max() / (S.min() + 1e-10)\n",
    "    stability_loss = torch.relu(S_ratio - 1e3) / 1e3\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 8. SMOOTHNESS REGULARIZATION (Stage 2 only)\n",
    "    # ========================================================================\n",
    "    if epoch > config['stage1_epochs']:\n",
    "        U_sorted = U_orth[:, sort_idx]\n",
    "        smoothness_loss = torch.mean(torch.sum((U_sorted[:, 1:] - U_sorted[:, :-1]) ** 2, dim=0))\n",
    "    else:\n",
    "        smoothness_loss = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ADAPTIVE WEIGHTING (Two-stage)\n",
    "    # ========================================================================\n",
    "    if epoch <= config['stage1_epochs']:\n",
    "        # Stage 1: Establish orthogonality, find low modes, force λ₁=0\n",
    "        w_zero = 100.0\n",
    "        w_trace = 5.0\n",
    "        w_div = 2.0\n",
    "        w_offdiag = 10.0\n",
    "        w_orth = 5.0\n",
    "        w_order = 0.5\n",
    "        w_stability = 0.1\n",
    "        w_smooth = 0.0\n",
    "    else:\n",
    "        # Stage 2: Fine-tune all eigenvalues, maintain constraints\n",
    "        w_zero = 50.0\n",
    "        w_trace = 2.0\n",
    "        w_div = 1.0\n",
    "        w_offdiag = 15.0\n",
    "        w_orth = 2.0\n",
    "        w_order = 0.2\n",
    "        w_stability = 0.1\n",
    "        w_smooth = 0.1\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = (w_zero * zero_eig_loss +\n",
    "                  w_trace * trace_loss +\n",
    "                  w_div * diversity_loss +\n",
    "                  w_offdiag * off_diag_loss +\n",
    "                  w_orth * orth_loss +\n",
    "                  w_order * ordering_loss +\n",
    "                  w_stability * stability_loss +\n",
    "                  w_smooth * smoothness_loss)\n",
    "    \n",
    "    # Components for logging\n",
    "    components = {\n",
    "        'zero_eig': zero_eig_loss.item(),\n",
    "        'trace': trace_loss.item(),\n",
    "        'diversity': diversity_loss.item(),\n",
    "        'offdiag': off_diag_loss.item(),\n",
    "        'orth': orth_loss.item(),\n",
    "        'order': ordering_loss.item(),\n",
    "        'stability': stability_loss.item(),\n",
    "        'smooth': smoothness_loss.item(),\n",
    "        'svd_cond': S_ratio.item(),\n",
    "    }\n",
    "    \n",
    "    return total_loss, components\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING SETUP\n",
    "# ============================================================================\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr_stage1'], weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=10000, T_mult=2, eta_min=CONFIG['lr_min']\n",
    ")\n",
    "\n",
    "loss_history = []\n",
    "best_loss = float('inf')\n",
    "no_improve_count = 0\n",
    "checkpoint_dir = Path('checkpoints')\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP (Your SVD orthogonalization + My improvements)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HYBRID TRAINING START\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Strategy: SVD orthogonalization + Fourier features + Two-stage training\")\n",
    "print(f\"Stage 1: 0-{CONFIG['stage1_epochs']:,} | Stage 2: {CONFIG['stage1_epochs']:,}-{CONFIG['max_epochs']:,}\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for epoch in range(1, CONFIG['max_epochs'] + 1):\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE TRANSITION\n",
    "    # ========================================================================\n",
    "    if epoch == CONFIG['stage1_epochs'] + 1:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STAGE 2: Fine-tuning all eigenvalues\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = CONFIG['lr_stage2']\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=CONFIG['max_epochs'] - CONFIG['stage1_epochs'],\n",
    "            eta_min=CONFIG['lr_min']\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FORWARD PASS WITH SVD ORTHOGONALIZATION (Your approach)\n",
    "    # ========================================================================\n",
    "    model.train()\n",
    "    \n",
    "    U = model(X)  # (N, k)\n",
    "    \n",
    "    # SVD-based M-orthogonalization\n",
    "    B = U.T @ (M @ U)  # Gram matrix\n",
    "    V, S, _ = torch.linalg.svd(B)\n",
    "    \n",
    "    # Compute B^(-1/2)\n",
    "    S_inv_sqrt = torch.diag_embed(1.0 / torch.sqrt(torch.clamp(S, min=1e-7)))\n",
    "    B_inv_sqrt = V @ S_inv_sqrt @ V.T\n",
    "    U_orth = U @ B_inv_sqrt  # M-orthonormal basis\n",
    "    \n",
    "    # Rayleigh quotient\n",
    "    rayleigh_matrix = U_orth.T @ (K @ U_orth)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOSS COMPUTATION\n",
    "    # ========================================================================\n",
    "    optimizer.zero_grad()\n",
    "    loss, loss_components = compute_loss(\n",
    "        U, U_orth, K, M, rayleigh_matrix, B, S, eigvals, epoch, CONFIG\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BACKWARD PASS\n",
    "    # ========================================================================\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['grad_clip'])\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOGGING\n",
    "    # ========================================================================\n",
    "    if epoch % CONFIG['print_every'] == 0 or epoch == 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get eigenvalues in original scale\n",
    "            approx_eigs = torch.diag(rayleigh_matrix).cpu().numpy()\n",
    "            approx_eigs.sort()\n",
    "            approx_eigs_original = approx_eigs * (K_scale / M_scale).cpu().numpy()\n",
    "            \n",
    "            # Compute errors\n",
    "            abs_error = np.abs(approx_eigs_original[:k] - eigvals[:k])\n",
    "            rel_error = abs_error / (np.abs(eigvals[:k]) + 1e-10)\n",
    "            mean_rel_error = np.mean(rel_error)\n",
    "            median_rel_error = np.median(rel_error)\n",
    "            \n",
    "            # Orthogonality check\n",
    "            B_orth = U_orth.T @ (M @ U_orth)\n",
    "            orth_residual = torch.norm(B_orth - torch.eye(k, device=device, dtype=torch.float64), p='fro').item()\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            stage = \"Stage1\" if epoch <= CONFIG['stage1_epochs'] else \"Stage2\"\n",
    "        \n",
    "        print(f\"[{stage}] Epoch {epoch:>6} | LR={current_lr:.6f}\")\n",
    "        print(f\"  Loss={loss.item():.6f} | λ₁²={loss_components['zero_eig']:.2e} | Trace={loss_components['trace']:.3f}\")\n",
    "        print(f\"  Orth={orth_residual:.2e} | OffDiag={loss_components['offdiag']:.2e} | SVD_cond={loss_components['svd_cond']:.2e}\")\n",
    "        print(f\"  MeanRelErr={mean_rel_error:.4%} | MedianRelErr={median_rel_error:.4%}\")\n",
    "        print(f\"  λ∈[{approx_eigs_original[0]:.6f}, {approx_eigs_original[-1]:.6f}]\")\n",
    "        \n",
    "        if epoch % (CONFIG['print_every'] * 5) == 0:\n",
    "            print(f\"  First 5 - Pred: {approx_eigs_original[:5]}\")\n",
    "            print(f\"  First 5 - True: {eigvals[:5]}\")\n",
    "            print(f\"  Last  5 - Pred: {approx_eigs_original[-5:]}\")\n",
    "            print(f\"  Last  5 - True: {eigvals[k-5:k]}\")\n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CHECKPOINTING & EARLY STOPPING\n",
    "    # ========================================================================\n",
    "    if epoch % CONFIG['checkpoint_every'] == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'loss_history': loss_history,\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_dir / f'checkpoint_epoch_{epoch}.pt')\n",
    "        \n",
    "        if loss.item() < best_loss * CONFIG['early_stopping_threshold']:\n",
    "            best_loss = loss.item()\n",
    "            no_improve_count = 0\n",
    "            torch.save(checkpoint, checkpoint_dir / 'best_model.pt')\n",
    "            print(f\"  ✓ New best model (loss={best_loss:.6f})\")\n",
    "        else:\n",
    "            no_improve_count += CONFIG['checkpoint_every']\n",
    "        \n",
    "        if no_improve_count >= CONFIG['early_stopping_patience']:\n",
    "            print(f\"\\n⚠ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading best model...\")\n",
    "best_checkpoint = torch.load(checkpoint_dir / 'best_model.pt')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    U_final = model(X)\n",
    "    \n",
    "    # Final SVD orthogonalization\n",
    "    B_final = U_final.T @ (M @ U_final)\n",
    "    V_final, S_final, _ = torch.linalg.svd(B_final)\n",
    "    S_inv_sqrt_final = torch.diag_embed(1.0 / torch.sqrt(torch.clamp(S_final, min=1e-7)))\n",
    "    B_inv_sqrt_final = V_final @ S_inv_sqrt_final @ V_final.T\n",
    "    U_orth_final = U_final @ B_inv_sqrt_final\n",
    "    \n",
    "    # Final matrices\n",
    "    final_rayleigh = U_orth_final.T @ (K @ U_orth_final)\n",
    "    final_ortho = U_orth_final.T @ (M @ U_orth_final)\n",
    "    \n",
    "    # Eigenvalues\n",
    "    final_eigs = torch.diag(final_rayleigh).cpu().numpy()\n",
    "    final_eigs.sort()\n",
    "    final_eigs_original = final_eigs * (K_scale / M_scale).cpu().numpy()\n",
    "    \n",
    "    # Errors\n",
    "    abs_error = np.abs(final_eigs_original - eigvals[:k])\n",
    "    rel_error = abs_error / (np.abs(eigvals[:k]) + 1e-10)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Orthogonality\n",
    "    identity_k = torch.eye(k, device=device, dtype=torch.float64)\n",
    "    orth_residual = torch.norm(final_ortho - identity_k, p='fro').item()\n",
    "    orth_diag = torch.diag(final_ortho).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\n Orthogonality Quality:\")\n",
    "    print(f\"  ||U^T M U - I||_F = {orth_residual:.2e}\")\n",
    "    print(f\"  Diagonal range: [{orth_diag.min():.6f}, {orth_diag.max():.6f}]\")\n",
    "    \n",
    "    # Rayleigh matrix\n",
    "    rayleigh_diag = torch.diag(final_rayleigh).cpu().numpy()\n",
    "    rayleigh_offdiag = (final_rayleigh - torch.diag(torch.diag(final_rayleigh))).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\n Rayleigh Matrix:\")\n",
    "    print(f\"  Diagonal norm: {np.linalg.norm(rayleigh_diag):.6f}\")\n",
    "    print(f\"  Off-diagonal norm: {np.linalg.norm(rayleigh_offdiag, 'fro'):.2e}\")\n",
    "    \n",
    "    # SVD condition\n",
    "    print(f\"\\n SVD Stability:\")\n",
    "    print(f\"  Condition number: {S_final.max().item() / S_final.min().item():.2e}\")\n",
    "    \n",
    "    # Eigenvalue comparison\n",
    "    print(f\"\\n Eigenvalue Comparison (First 10):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<14} {'Reference':<14} {'Abs Error':<14} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(min(10, k)):\n",
    "        print(f\"{i+1:<6} {final_eigs_original[i]:<14.8f} {eigvals[i]:<14.8f} \"\n",
    "              f\"{abs_error[i]:<14.8f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    print(f\"\\n Eigenvalue Comparison (Last 10):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<14} {'Reference':<14} {'Abs Error':<14} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(max(0, k-10), k):\n",
    "        print(f\"{i+1:<6} {final_eigs_original[i]:<14.8f} {eigvals[i]:<14.8f} \"\n",
    "              f\"{abs_error[i]:<14.8f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\n Overall Statistics ({k} modes):\")\n",
    "    print(f\"  Mean Absolute Error:     {np.mean(abs_error):.8f}\")\n",
    "    print(f\"  Mean Relative Error:     {np.mean(rel_error):.4%}\")\n",
    "    print(f\"  Median Relative Error:   {np.median(rel_error):.4%}\")\n",
    "    print(f\"  Max Relative Error:      {np.max(rel_error):.4%}\")\n",
    "    print(f\"  Modes with <1% error:    {np.sum(rel_error < 0.01)}/{k}\")\n",
    "    print(f\"  Modes with <5% error:    {np.sum(rel_error < 0.05)}/{k}\")\n",
    "    print(f\"  Modes with <10% error:   {np.sum(rel_error < 0.10)}/{k}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'final_eigenvalues': final_eigs_original,\n",
    "    'reference_eigenvalues': eigvals[:k],\n",
    "    'errors': {'absolute': abs_error, 'relative': rel_error},\n",
    "    'normalization': {'K_scale': K_scale.item(), 'M_scale': M_scale.item()},\n",
    "}, 'hybrid_model_final.pt')\n",
    "\n",
    "print(\"\\n✓ Model saved to 'hybrid_model_final.pt'\")\n",
    "print(\"✓ Checkpoints in 'checkpoints/' directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
