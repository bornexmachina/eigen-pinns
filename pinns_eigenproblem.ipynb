{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53342ca8-db05-456c-8e2b-5fc44e26698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc22b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors (double precision for better numerical stability)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70dc13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Laplacian\n",
      "Computing eigen values\n"
     ]
    }
   ],
   "source": [
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "\n",
    "verts_new = (m.verts - centroid)/std_max\n",
    "\n",
    "m = Mesh(verts = verts_new, connectivity = m.connectivity)\n",
    "\n",
    "print('Computing Laplacian')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "# following Finite Elements methodology \n",
    "# K is stiffness matrix, M is mass matrix\n",
    "# The problem to solve becomes \n",
    "# K*u = lambda * M*u\n",
    "print('Computing eigen values')\n",
    "eigvals, eigvecs = linalg.eigh(K,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42393004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send all relevant numpy arrays to torch tensors\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e635ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper we used 50 eigenvalues so set k to 50\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018a8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1, loss=1368.665551\n",
      "Epoch 1000, loss=2066.030754\n",
      "Epoch 2000, loss=1912.940066\n",
      "Epoch 3000, loss=1843.071664\n",
      "Epoch 4000, loss=1794.844967\n",
      "Epoch 5000, loss=1764.853150\n",
      "Epoch 6000, loss=1743.827595\n",
      "Epoch 7000, loss=1701.613736\n",
      "Epoch 8000, loss=1676.294465\n",
      "Epoch 9000, loss=1662.250554\n",
      "Epoch 10000, loss=1646.344673\n",
      "Epoch 11000, loss=1635.926793\n",
      "Epoch 12000, loss=1624.898667\n",
      "Epoch 13000, loss=1618.154888\n",
      "Epoch 14000, loss=1611.124786\n",
      "Epoch 15000, loss=1603.269654\n",
      "Epoch 16000, loss=1598.331131\n",
      "Epoch 17000, loss=1596.705161\n",
      "Epoch 18000, loss=1590.091182\n",
      "Epoch 19000, loss=1585.239140\n",
      "Epoch 20000, loss=1584.945676\n",
      "Epoch 21000, loss=1579.458842\n",
      "Epoch 22000, loss=1575.208811\n",
      "Epoch 23000, loss=1573.211510\n",
      "Epoch 24000, loss=1568.768129\n",
      "Epoch 25000, loss=1566.581510\n",
      "Epoch 26000, loss=1566.542304\n",
      "Epoch 27000, loss=1562.922383\n",
      "Epoch 28000, loss=1560.906528\n",
      "Epoch 29000, loss=1557.691642\n",
      "Epoch 30000, loss=1556.045037\n",
      "Epoch 31000, loss=1555.132180\n",
      "Epoch 32000, loss=1552.917258\n",
      "Epoch 33000, loss=1551.027162\n",
      "Epoch 34000, loss=1549.639207\n",
      "Epoch 35000, loss=1548.223452\n",
      "Epoch 36000, loss=1546.783657\n",
      "Epoch 37000, loss=1545.939718\n",
      "Epoch 38000, loss=1543.934079\n",
      "Epoch 39000, loss=1543.268817\n",
      "Epoch 40000, loss=1541.997958\n",
      "Epoch 41000, loss=1540.699829\n",
      "Epoch 42000, loss=1539.810541\n",
      "Epoch 43000, loss=1538.940981\n",
      "Epoch 44000, loss=1538.326817\n",
      "Epoch 45000, loss=1537.386321\n",
      "Epoch 46000, loss=1537.128289\n",
      "Epoch 47000, loss=1535.550876\n",
      "Epoch 48000, loss=1534.888777\n",
      "Epoch 49000, loss=1534.196383\n",
      "Epoch 50000, loss=1533.661804\n",
      "Epoch 51000, loss=1532.558773\n",
      "Epoch 52000, loss=1531.784283\n",
      "Epoch 53000, loss=1531.123198\n",
      "Epoch 54000, loss=1530.726041\n",
      "Epoch 55000, loss=1530.428561\n",
      "Epoch 56000, loss=1529.376569\n",
      "Epoch 57000, loss=1528.881139\n",
      "Epoch 58000, loss=1528.597382\n",
      "Epoch 59000, loss=1527.855551\n",
      "Epoch 60000, loss=1527.515116\n",
      "Epoch 61000, loss=1526.977346\n",
      "Epoch 62000, loss=1526.508319\n",
      "Epoch 63000, loss=1526.076017\n",
      "Epoch 64000, loss=1525.674650\n",
      "Epoch 65000, loss=1525.197985\n",
      "Epoch 66000, loss=1525.407088\n",
      "Epoch 67000, loss=1524.483476\n",
      "Epoch 68000, loss=1524.528498\n",
      "Epoch 69000, loss=1523.914440\n",
      "Epoch 70000, loss=1523.338478\n",
      "Epoch 71000, loss=1523.039023\n",
      "Epoch 72000, loss=1522.724902\n",
      "Epoch 73000, loss=1522.541932\n",
      "Epoch 74000, loss=1522.273957\n",
      "Epoch 75000, loss=1521.709958\n",
      "Epoch 76000, loss=1521.369813\n",
      "Epoch 77000, loss=1521.073278\n",
      "Epoch 78000, loss=1520.831800\n",
      "Epoch 79000, loss=1520.497698\n",
      "Epoch 80000, loss=1520.226197\n",
      "Epoch 81000, loss=1519.936942\n",
      "Epoch 82000, loss=1519.639368\n",
      "Epoch 83000, loss=1519.389050\n",
      "Epoch 84000, loss=1519.091876\n",
      "Epoch 85000, loss=1519.008476\n",
      "Epoch 86000, loss=1518.583754\n",
      "Epoch 87000, loss=1518.331954\n",
      "Epoch 88000, loss=1518.087927\n",
      "Epoch 89000, loss=1518.034061\n",
      "Epoch 90000, loss=1517.614269\n",
      "Epoch 91000, loss=1517.406820\n",
      "Epoch 92000, loss=1517.167121\n",
      "Epoch 93000, loss=1516.940060\n",
      "Epoch 94000, loss=1516.737533\n",
      "Epoch 95000, loss=1516.514015\n",
      "Epoch 96000, loss=1516.304186\n",
      "Epoch 97000, loss=1516.157307\n",
      "Epoch 98000, loss=1515.899675\n",
      "Epoch 99000, loss=1515.760214\n",
      "Epoch 100000, loss=1515.516558\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network that maps coordinates -> k outputs per node\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=k, hidden=[64,64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last, h, dtype=torch.double))\n",
    "            layers.append(nn.SiLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, out_dim, dtype=torch.double))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns (N, k)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "model = MLP().to(device)\n",
    "# Initialize all layers (Xavier), final layer small\n",
    "for name, p in model.named_parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "for p in model.net[-1].parameters():  # last Linear\n",
    "    if p.ndim == 2:\n",
    "        nn.init.normal_(p, std=1e-3)\n",
    "    else:\n",
    "        nn.init.zeros_(p)\n",
    "\n",
    "# Helper: given A (N x k), return M-orthonormalized U = A (A^T M A)^{-1/2}\n",
    "def m_orthonormalize(A, M):\n",
    "    # A: (N, k), M: (N, N)\n",
    "    # compute B = A^T M A (k x k)\n",
    "    B = A.T @ (M @ A)  # k x k\n",
    "    # symmetrize B\n",
    "    B = 0.5*(B + B.T)\n",
    "    # compute inverse sqrt of B via eigendecomposition (k small)\n",
    "    s, Q = torch.linalg.eigh(B)  # s are eigenvalues\n",
    "    # regularize small eigenvalues\n",
    "    s_clamped = torch.clamp(s, min=1e-12)\n",
    "    inv_sqrt = Q @ torch.diag(1.0/torch.sqrt(s_clamped)) @ Q.T\n",
    "    U = A @ inv_sqrt\n",
    "    return U\n",
    "\n",
    "lr_start = 0.01\n",
    "lr_end = 0.0001\n",
    "max_epochs = 100_000\n",
    "print_every = 1_000\n",
    "loss_history = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_start)\n",
    "decay_factor = (lr_end / lr_start) ** (1 / max_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_factor)\n",
    "\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    A = model(X)  # N x k\n",
    "    U = m_orthonormalize(A, M)  # U is M-orthonormal\n",
    "\n",
    "    UKU = U.T @ (K @ U)\n",
    "    UMU = U.T @ (M @ U)        # k x k\n",
    "    \n",
    "    orth_loss = torch.norm(UMU - torch.eye(k, device=device), p='fro')**2\n",
    "    eig_loss = torch.norm(UKU, p='fro')**2\n",
    "\n",
    "    loss = eig_loss + orth_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    loss_history.append(loss.item())\n",
    "    if epoch % print_every == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:4d}, loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46439ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of U.t @ K @ U is: torch.Size([50, 50])\n",
      "\n",
      "Learned Ritz values (from U^T K U): [0.001545 0.251101 0.279114 0.410295 0.528886]\n",
      "Reference eigenvalues (first k):    [0.       0.007574 0.030308 0.068146 0.121208]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    A_final = model(X)\n",
    "\n",
    "    U_final= m_orthonormalize(A_final, M)\n",
    "    UKU = U_final.T @ (K @ U_final)\n",
    "\n",
    "    print(f\"The shape of U.t @ K @ U is: {UKU.shape}\")\n",
    "\n",
    "    approx_eigs = np.round(torch.diag(UKU).cpu().numpy(), 8)\n",
    "    # For better comparison, we can compute Ritz values from subspace U by solving small generalized eigenproblem\n",
    "    # (U^T K U) c = mu (U^T M U) c, but U^T M U = I so just eig of UK_final\n",
    "    mu, Wsmall = np.linalg.eigh(UKU.cpu().numpy())\n",
    "    mu = np.real(mu)\n",
    "    # sort\n",
    "    idx = np.argsort(mu)\n",
    "    mu = mu[idx]\n",
    "    print(\"\\nLearned Ritz values (from U^T K U):\", np.round(mu[:5], 6))\n",
    "    print(\"Reference eigenvalues (first k):   \", np.round(eigvals[:5], 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105bee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- approximation: 0.0015 actual: 0.0 ---\n",
      "--- approximation: 0.2511 actual: 0.0076 ---\n",
      "--- approximation: 0.2791 actual: 0.0303 ---\n",
      "--- approximation: 0.4103 actual: 0.0681 ---\n",
      "--- approximation: 0.5289 actual: 0.1212 ---\n",
      "--- approximation: 0.5451 actual: 0.1892 ---\n",
      "--- approximation: 0.731 actual: 0.2722 ---\n",
      "--- approximation: 0.8444 actual: 0.3705 ---\n",
      "--- approximation: 1.0492 actual: 0.4834 ---\n",
      "--- approximation: 1.1186 actual: 0.6113 ---\n",
      "--- approximation: 1.1889 actual: 0.754 ---\n",
      "--- approximation: 1.3851 actual: 0.9117 ---\n",
      "--- approximation: 1.7263 actual: 1.0836 ---\n",
      "--- approximation: 1.7938 actual: 1.27 ---\n",
      "--- approximation: 2.3232 actual: 1.4713 ---\n",
      "--- approximation: 2.4727 actual: 1.687 ---\n",
      "--- approximation: 2.5082 actual: 1.9172 ---\n",
      "--- approximation: 2.6524 actual: 2.1605 ---\n",
      "--- approximation: 2.8541 actual: 2.419 ---\n",
      "--- approximation: 3.1354 actual: 2.6903 ---\n",
      "--- approximation: 3.6757 actual: 2.9745 ---\n",
      "--- approximation: 3.8079 actual: 3.2753 ---\n",
      "--- approximation: 4.2216 actual: 3.587 ---\n",
      "--- approximation: 4.3398 actual: 3.9143 ---\n",
      "--- approximation: 4.3585 actual: 4.2555 ---\n",
      "--- approximation: 5.0145 actual: 4.6071 ---\n",
      "--- approximation: 5.5674 actual: 4.9696 ---\n",
      "--- approximation: 5.8745 actual: 5.3506 ---\n",
      "--- approximation: 6.3597 actual: 5.7442 ---\n",
      "--- approximation: 6.5781 actual: 6.1454 ---\n",
      "--- approximation: 6.6584 actual: 6.5674 ---\n",
      "--- approximation: 7.3101 actual: 6.9955 ---\n",
      "--- approximation: 7.349 actual: 7.2276 ---\n",
      "--- approximation: 7.3547 actual: 7.2332 ---\n",
      "--- approximation: 7.4001 actual: 7.2643 ---\n",
      "--- approximation: 7.4858 actual: 7.301 ---\n",
      "--- approximation: 7.546 actual: 7.3609 ---\n",
      "--- approximation: 7.5787 actual: 7.3633 ---\n",
      "--- approximation: 7.6477 actual: 7.3767 ---\n",
      "--- approximation: 7.6702 actual: 7.4047 ---\n",
      "--- approximation: 7.7284 actual: 7.4222 ---\n",
      "--- approximation: 7.7409 actual: 7.4495 ---\n",
      "--- approximation: 7.7963 actual: 7.4556 ---\n",
      "--- approximation: 7.8903 actual: 7.5081 ---\n",
      "--- approximation: 7.9116 actual: 7.5268 ---\n",
      "--- approximation: 7.9776 actual: 7.6074 ---\n",
      "--- approximation: 8.0269 actual: 7.6143 ---\n",
      "--- approximation: 8.217 actual: 7.7081 ---\n",
      "--- approximation: 8.6576 actual: 7.7249 ---\n",
      "--- approximation: 8.744 actual: 7.8346 ---\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(mu, eigvals):\n",
    "    print(f\"--- approximation: {np.round(i, 4)} actual: {np.round(j, 4)} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
    "surf = ax.plot_trisurf(m.verts[:,0], m.verts[:,1], m.verts[:,2], triangles = m.connectivity)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
