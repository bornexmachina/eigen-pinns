{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53342ca8-db05-456c-8e2b-5fc44e26698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc22b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors (double precision for better numerical stability)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70dc13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Laplacian\n",
      "Computing eigen values\n"
     ]
    }
   ],
   "source": [
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "\n",
    "verts_new = (m.verts - centroid)/std_max\n",
    "\n",
    "m = Mesh(verts = verts_new, connectivity = m.connectivity)\n",
    "\n",
    "print('Computing Laplacian')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "# following Finite Elements methodology \n",
    "# K is stiffness matrix, M is mass matrix\n",
    "# The problem to solve becomes \n",
    "# K*u = lambda * M*u\n",
    "print('Computing eigen values')\n",
    "eigvals, eigvecs = linalg.eigh(K,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42393004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send all relevant numpy arrays to torch tensors\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e635ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper we used 50 eigenvalues so set k to 50\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1, loss=195.006185\n",
      "Epoch 1000, loss=271.388413\n",
      "Epoch 2000, loss=261.308455\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network that maps coordinates -> k outputs per node\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=k, hidden=[64,64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last, h, dtype=torch.double))\n",
    "            layers.append(nn.SiLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, out_dim, dtype=torch.double))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns (N, k)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "model = MLP().to(device)\n",
    "# Initialize all layers (Xavier), final layer small\n",
    "for name, p in model.named_parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "for p in model.net[-1].parameters():  # last Linear\n",
    "    if p.ndim == 2:\n",
    "        nn.init.normal_(p, std=1e-3)\n",
    "    else:\n",
    "        nn.init.zeros_(p)\n",
    "\n",
    "# Helper: given A (N x k), return M-orthonormalized U = A (A^T M A)^{-1/2}\n",
    "def m_orthonormalize(A, M):\n",
    "    # A: (N, k), M: (N, N)\n",
    "    # compute B = A^T M A (k x k)\n",
    "    B = A.T @ (M @ A)  # k x k\n",
    "    # symmetrize B\n",
    "    B = 0.5*(B + B.T)\n",
    "    # compute inverse sqrt of B via eigendecomposition (k small)\n",
    "    s, Q = torch.linalg.eigh(B)  # s are eigenvalues\n",
    "    # regularize small eigenvalues\n",
    "    s_clamped = torch.clamp(s, min=1e-12)\n",
    "    inv_sqrt = Q @ torch.diag(1.0/torch.sqrt(s_clamped)) @ Q.T\n",
    "    U = A @ inv_sqrt\n",
    "    return U\n",
    "\n",
    "lr_start = 0.01\n",
    "lr_end = 0.0001\n",
    "max_epochs = 100_000\n",
    "print_every = 1_000\n",
    "loss_history = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_start)\n",
    "decay_factor = (lr_end / lr_start) ** (1 / max_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_factor)\n",
    "\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    A = model(X)  # N x k\n",
    "    U = m_orthonormalize(A, M)  # U is M-orthonormal\n",
    "\n",
    "    UKU = U.T @ (K @ U)\n",
    "    # symmetrize for numerical safety\n",
    "    UKU = 0.5*(UKU + UKU.T)\n",
    "    loss = torch.trace(UKU)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    loss_history.append(loss.item())\n",
    "    if epoch % print_every == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:4d}, loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46439ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    A_final = model(X)\n",
    "\n",
    "    U_final= m_orthonormalize(A_final, M)\n",
    "    UKU = U_final.T @ (K @ U_final)\n",
    "\n",
    "    print(f\"The shape of U.t @ K @ U is: {UKU.shape}\")\n",
    "\n",
    "    approx_eigs = np.round(torch.diag(UKU).cpu().numpy(), 8)\n",
    "    # For better comparison, we can compute Ritz values from subspace U by solving small generalized eigenproblem\n",
    "    # (U^T K U) c = mu (U^T M U) c, but U^T M U = I so just eig of UK_final\n",
    "    mu, Wsmall = np.linalg.eigh(UKU.cpu().numpy())\n",
    "    mu = np.real(mu)\n",
    "    # sort\n",
    "    idx = np.argsort(mu)\n",
    "    mu = mu[idx]\n",
    "    print(\"\\nLearned Ritz values (from U^T K U):\", np.round(mu[:5], 6))\n",
    "    print(\"Reference eigenvalues (first k):   \", np.round(eigvals[:5], 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
    "surf = ax.plot_trisurf(m.verts[:,0], m.verts[:,1], m.verts[:,2], triangles = m.connectivity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662dbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "A_final = model(X)\n",
    "U_final = m_orthonormalize(A_final, M)\n",
    "\n",
    "\n",
    "Ksmall = U_final.T @ K @ U_final\n",
    "Msmall = U_final.T @ M @ U_final\n",
    "L = torch.linalg.cholesky(Msmall)\n",
    "Linv = torch.linalg.inv(L)\n",
    "Khat = Linv @ Ksmall @ Linv.T\n",
    "mu, _ = torch.linalg.eigh(Khat)\n",
    "\n",
    "\n",
    "mu = mu.cpu().numpy()\n",
    "idx = np.argsort(mu)\n",
    "mu = mu[idx]\n",
    "\n",
    "\n",
    "print(f\"The shape of U.T @ K @ U is: {U_final.T @ K @ U_final.shape}\")\n",
    "print(\"\\nLearned Ritz values (from U^T K U):\", np.round(mu[:5], 6))\n",
    "print(\"Reference eigenvalues (first k): \", np.round(eigvals[:5], 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
