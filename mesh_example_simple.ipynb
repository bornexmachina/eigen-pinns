{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8a717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e27da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors (double precision for better numerical stability)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d16402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Laplacian\n",
      "Computing eigen values\n"
     ]
    }
   ],
   "source": [
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "\n",
    "verts_new = (m.verts - centroid)/std_max\n",
    "\n",
    "m = Mesh(verts = verts_new, connectivity = m.connectivity)\n",
    "\n",
    "print('Computing Laplacian')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "# following Finite Elements methodology \n",
    "# K is stiffness matrix, M is mass matrix\n",
    "# The problem to solve becomes \n",
    "# K*u = lambda * M*u\n",
    "print('Computing eigen values')\n",
    "eigvals, eigvecs = linalg.eigh(K,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abff7e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using epsilon=0.0001, final condition number: 1.47e+05\n",
      "\n",
      "=== Matrix Normalization ===\n"
     ]
    }
   ],
   "source": [
    "# send all relevant numpy arrays to torch tensors\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)\n",
    "N = X.shape[0]\n",
    "\n",
    "\n",
    "# 1. Start with stronger regularization\n",
    "epsilon = 1e-4\n",
    "\n",
    "# Apply the regularization\n",
    "K_reg = K + epsilon * torch.eye(N, device=device)\n",
    "print(f\"\\nUsing epsilon={epsilon}, final condition number: {torch.linalg.cond(K_reg).item():.2e}\")\n",
    "\n",
    "print(\"\\n=== Matrix Normalization ===\")\n",
    "K_scale = torch.norm(K_reg, p='fro')\n",
    "M_scale = torch.norm(M, p='fro')\n",
    "\n",
    "K = K_reg / K_scale\n",
    "M = M / K_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653bef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper we used 50 eigenvalues so set k to 50\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network that maps coordinates -> k outputs per node\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=k, hidden=[64,64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last, h, dtype=torch.double))\n",
    "            layers.append(nn.SiLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, out_dim, dtype=torch.double))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns (N, k)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "model = MLP().to(device)\n",
    "# Initialize all layers (Xavier), final layer small\n",
    "for name, p in model.named_parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "for p in model.net[-1].parameters():  # last Linear\n",
    "    if p.ndim == 2:\n",
    "        nn.init.normal_(p, std=1e-3)\n",
    "    else:\n",
    "        nn.init.zeros_(p)\n",
    "\n",
    "lr_start = 0.05\n",
    "lr_end = 0.001\n",
    "max_epochs = 100_000\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr_start, weight_decay=1e-5)\n",
    "\n",
    "# Cosine annealing with warm restarts for better convergence\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=30000, T_mult=2, eta_min=lr_end)\n",
    "print_every = 1_000\n",
    "loss_history = []\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "#decay_factor = (lr_end / lr_start) ** (1 / max_epochs)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1a1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total loss=500.021039, eig_loss=0.024632, orth_loss=49.999641\n",
      "Epoch 1000, total loss=453.643545, eig_loss=21.684457, orth_loss=43.195909\n",
      "Epoch 2000, total loss=434.481217, eig_loss=38.047090, orth_loss=39.643413\n",
      "Epoch 3000, total loss=1018.130197, eig_loss=604.390280, orth_loss=41.373992\n",
      "Epoch 4000, total loss=518.048194, eig_loss=69.187764, orth_loss=44.886043\n",
      "Epoch 5000, total loss=484.558249, eig_loss=28.852698, orth_loss=45.570555\n",
      "Epoch 6000, total loss=476.662288, eig_loss=19.774643, orth_loss=45.688764\n",
      "Epoch 7000, total loss=473.327488, eig_loss=17.747808, orth_loss=45.557968\n",
      "Epoch 8000, total loss=470.974342, eig_loss=17.748498, orth_loss=45.322584\n",
      "Epoch 9000, total loss=469.038847, eig_loss=17.416100, orth_loss=45.162275\n",
      "Epoch 10000, total loss=466.678177, eig_loss=17.353933, orth_loss=44.932424\n",
      "Epoch 11000, total loss=464.419860, eig_loss=18.267429, orth_loss=44.615243\n",
      "Epoch 12000, total loss=462.209522, eig_loss=18.455048, orth_loss=44.375447\n",
      "Epoch 13000, total loss=458.595857, eig_loss=18.577633, orth_loss=44.001822\n",
      "Epoch 14000, total loss=446.593619, eig_loss=24.628726, orth_loss=42.196489\n",
      "Epoch 15000, total loss=439.812039, eig_loss=24.193907, orth_loss=41.561813\n",
      "Epoch 16000, total loss=432.312042, eig_loss=25.132133, orth_loss=40.717991\n",
      "Epoch 17000, total loss=491.995457, eig_loss=35.148466, orth_loss=45.684699\n",
      "Epoch 18000, total loss=477.552447, eig_loss=17.914748, orth_loss=45.963770\n",
      "Epoch 19000, total loss=473.328279, eig_loss=15.062882, orth_loss=45.826540\n",
      "Epoch 20000, total loss=471.128095, eig_loss=14.568175, orth_loss=45.655992\n",
      "Epoch 21000, total loss=466.914786, eig_loss=13.414266, orth_loss=45.350052\n",
      "Epoch 22000, total loss=463.816896, eig_loss=12.128301, orth_loss=45.168859\n",
      "Epoch 23000, total loss=461.920805, eig_loss=13.047122, orth_loss=44.887368\n",
      "Epoch 24000, total loss=455.251930, eig_loss=15.652599, orth_loss=43.959933\n",
      "Epoch 25000, total loss=445.933050, eig_loss=19.490933, orth_loss=42.644212\n",
      "Epoch 26000, total loss=438.637825, eig_loss=16.131563, orth_loss=42.250626\n",
      "Epoch 27000, total loss=430.294566, eig_loss=17.002060, orth_loss=41.329251\n",
      "Epoch 28000, total loss=426.425297, eig_loss=14.786343, orth_loss=41.163895\n",
      "Epoch 29000, total loss=418.245079, eig_loss=20.846447, orth_loss=39.739863\n",
      "Epoch 30000, total loss=413.965241, eig_loss=21.497050, orth_loss=39.246819\n",
      "Epoch 31000, total loss=1315.668429, eig_loss=904.977620, orth_loss=41.069081\n",
      "Epoch 32000, total loss=832.406641, eig_loss=413.915495, orth_loss=41.849115\n",
      "Epoch 33000, total loss=651.211514, eig_loss=218.282978, orth_loss=43.292854\n",
      "Epoch 34000, total loss=564.146051, eig_loss=120.423815, orth_loss=44.372224\n",
      "Epoch 35000, total loss=517.428140, eig_loss=66.329811, orth_loss=45.109833\n",
      "Epoch 36000, total loss=494.727135, eig_loss=39.197251, orth_loss=45.552988\n",
      "Epoch 37000, total loss=483.071730, eig_loss=25.208699, orth_loss=45.786303\n",
      "Epoch 38000, total loss=476.635294, eig_loss=17.914364, orth_loss=45.872093\n",
      "Epoch 39000, total loss=473.108641, eig_loss=14.834102, orth_loss=45.827454\n",
      "Epoch 40000, total loss=469.830775, eig_loss=12.255690, orth_loss=45.757509\n",
      "Epoch 41000, total loss=466.871797, eig_loss=12.178091, orth_loss=45.469371\n",
      "Epoch 42000, total loss=464.413512, eig_loss=14.959779, orth_loss=44.945373\n",
      "Epoch 43000, total loss=462.360239, eig_loss=17.753881, orth_loss=44.460636\n",
      "Epoch 44000, total loss=459.572552, eig_loss=18.076767, orth_loss=44.149578\n",
      "Epoch 45000, total loss=456.981947, eig_loss=20.170531, orth_loss=43.681142\n",
      "Epoch 46000, total loss=506.606741, eig_loss=44.959339, orth_loss=46.164740\n",
      "Epoch 47000, total loss=485.409243, eig_loss=18.797012, orth_loss=46.661223\n",
      "Epoch 48000, total loss=480.112389, eig_loss=13.083170, orth_loss=46.702922\n",
      "Epoch 49000, total loss=477.524528, eig_loss=11.420641, orth_loss=46.610389\n",
      "Epoch 50000, total loss=476.095764, eig_loss=10.759563, orth_loss=46.533620\n",
      "Epoch 51000, total loss=474.834932, eig_loss=10.364284, orth_loss=46.447065\n",
      "Epoch 52000, total loss=474.199206, eig_loss=10.318978, orth_loss=46.388023\n",
      "Epoch 53000, total loss=473.521746, eig_loss=10.916043, orth_loss=46.260570\n",
      "Epoch 54000, total loss=470.091496, eig_loss=14.944466, orth_loss=45.514703\n",
      "Epoch 55000, total loss=468.365417, eig_loss=15.253654, orth_loss=45.311176\n",
      "Epoch 56000, total loss=524.474836, eig_loss=72.211980, orth_loss=45.226286\n",
      "Epoch 57000, total loss=493.961405, eig_loss=37.473014, orth_loss=45.648839\n",
      "Epoch 58000, total loss=482.352602, eig_loss=25.357416, orth_loss=45.699519\n",
      "Epoch 59000, total loss=476.100176, eig_loss=20.570918, orth_loss=45.552926\n",
      "Epoch 60000, total loss=471.890286, eig_loss=19.208594, orth_loss=45.268169\n",
      "Epoch 61000, total loss=469.091227, eig_loss=19.852616, orth_loss=44.923861\n",
      "Epoch 62000, total loss=466.712526, eig_loss=20.909253, orth_loss=44.580327\n",
      "Epoch 63000, total loss=463.219750, eig_loss=21.310846, orth_loss=44.190890\n",
      "Epoch 64000, total loss=458.757110, eig_loss=20.766572, orth_loss=43.799054\n",
      "Epoch 65000, total loss=452.632300, eig_loss=21.075750, orth_loss=43.155655\n",
      "Epoch 66000, total loss=447.480102, eig_loss=23.575839, orth_loss=42.390426\n",
      "Epoch 67000, total loss=443.853040, eig_loss=23.587268, orth_loss=42.026577\n",
      "Epoch 68000, total loss=436.354398, eig_loss=22.010224, orth_loss=41.434417\n",
      "Epoch 69000, total loss=427.870170, eig_loss=22.394958, orth_loss=40.547521\n",
      "Epoch 70000, total loss=422.628652, eig_loss=23.767837, orth_loss=39.886082\n",
      "Epoch 71000, total loss=416.943426, eig_loss=26.540551, orth_loss=39.040287\n",
      "Epoch 72000, total loss=544.194447, eig_loss=117.289378, orth_loss=42.690507\n",
      "Epoch 73000, total loss=413.888127, eig_loss=32.480027, orth_loss=38.140810\n",
      "Epoch 74000, total loss=410.086791, eig_loss=31.347628, orth_loss=37.873916\n",
      "Epoch 75000, total loss=406.248238, eig_loss=29.378643, orth_loss=37.686960\n",
      "Epoch 76000, total loss=403.682395, eig_loss=30.909414, orth_loss=37.277298\n",
      "Epoch 77000, total loss=401.154538, eig_loss=33.006409, orth_loss=36.814813\n",
      "Epoch 78000, total loss=397.921088, eig_loss=36.293731, orth_loss=36.162736\n",
      "Epoch 79000, total loss=396.065306, eig_loss=35.777812, orth_loss=36.028749\n",
      "Epoch 80000, total loss=394.022384, eig_loss=36.104830, orth_loss=35.791755\n",
      "Epoch 81000, total loss=392.626603, eig_loss=38.840635, orth_loss=35.378597\n",
      "Epoch 82000, total loss=390.567280, eig_loss=38.369924, orth_loss=35.219736\n",
      "Epoch 83000, total loss=387.562247, eig_loss=41.390045, orth_loss=34.617220\n",
      "Epoch 84000, total loss=386.513822, eig_loss=42.030891, orth_loss=34.448293\n",
      "Epoch 85000, total loss=385.997554, eig_loss=42.501192, orth_loss=34.349636\n",
      "Epoch 86000, total loss=384.898217, eig_loss=45.870199, orth_loss=33.902802\n",
      "Epoch 87000, total loss=384.235259, eig_loss=46.185948, orth_loss=33.804931\n",
      "Epoch 88000, total loss=383.868035, eig_loss=46.255257, orth_loss=33.761278\n",
      "Epoch 89000, total loss=383.421407, eig_loss=46.332925, orth_loss=33.708848\n",
      "Epoch 90000, total loss=383.044365, eig_loss=46.405709, orth_loss=33.663866\n",
      "Epoch 91000, total loss=922.876421, eig_loss=527.276160, orth_loss=39.560026\n",
      "Epoch 92000, total loss=647.452783, eig_loss=226.313056, orth_loss=42.113973\n",
      "Epoch 93000, total loss=546.614285, eig_loss=108.975846, orth_loss=43.763844\n",
      "Epoch 94000, total loss=508.260568, eig_loss=61.685002, orth_loss=44.657557\n",
      "Epoch 95000, total loss=490.010521, eig_loss=38.413237, orth_loss=45.159728\n",
      "Epoch 96000, total loss=481.336702, eig_loss=27.383106, orth_loss=45.395360\n",
      "Epoch 97000, total loss=473.596108, eig_loss=18.925487, orth_loss=45.467062\n",
      "Epoch 98000, total loss=470.754829, eig_loss=16.920735, orth_loss=45.383409\n",
      "Epoch 99000, total loss=469.001051, eig_loss=17.229263, orth_loss=45.177179\n",
      "Epoch 100000, total loss=468.071122, eig_loss=17.895560, orth_loss=45.017556\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, max_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    U = model(X)  # N x k\n",
    "\n",
    "    # losses\n",
    "    UMU = U.T @ (M @ U)        # k x k\n",
    "    UKU = U.T @ (K @ U)\n",
    "\n",
    "    eigenvalues_approx = torch.diag(UKU)\n",
    "    sorted_eigs, _ = torch.sort(eigenvalues_approx)\n",
    "    zero_eig_loss = sorted_eigs[0] ** 2\n",
    "    eig_loss_trace = torch.sum(sorted_eigs[1:])\n",
    "    gaps = sorted_eigs[1:] - sorted_eigs[:-1]\n",
    "    min_gap = 1e-4  # Minimum separation in normalized units (very small)\n",
    "    diversity_loss = torch.sum(torch.relu(min_gap - gaps))\n",
    "    off_diag_mask = 1 - torch.eye(k, device=device, dtype=torch.float64)\n",
    "    eig_loss_offdiag = torch.sum((UKU * off_diag_mask)**2)\n",
    "\n",
    "\n",
    "    orth_loss = torch.norm(UMU - torch.eye(k, device=device), p='fro')**2\n",
    "    #eig_loss = torch.norm(UKU, p='fro')**2\n",
    "    eig_loss = 2*zero_eig_loss + 5*eig_loss_trace + 5*diversity_loss + eig_loss_offdiag\n",
    "\n",
    "    loss = eig_loss + 10 * orth_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    if epoch % print_every == 0 or epoch == 1:\n",
    "        approx_vals = torch.diag(U.T @ (K @ U)).detach().cpu().numpy()\n",
    "        print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"total loss={loss.item():.6f}, \"\n",
    "        f\"eig_loss={eig_loss.item():.6f}, \"\n",
    "        f\"orth_loss={orth_loss.item():.6f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfdfc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Eigenvalue Comparison (first 10 modes):\n",
      "Mode   Predicted    Reference    Abs Error    Rel Error   \n",
      "------------------------------------------------------------------\n",
      "1      0.001015     0.000000     0.001015     1011352243.9958%\n",
      "2      0.001172     0.007574     0.006402     84.5228%    \n",
      "3      0.001203     0.030308     0.029105     96.0300%    \n",
      "4      0.001301     0.068146     0.066846     98.0910%    \n",
      "5      0.001353     0.121208     0.119855     98.8840%    \n",
      "6      0.001386     0.189243     0.187857     99.2678%    \n",
      "7      0.001460     0.272231     0.270772     99.4638%    \n",
      "8      0.001489     0.370536     0.369047     99.5983%    \n",
      "9      0.001523     0.483409     0.481886     99.6849%    \n",
      "10     0.001559     0.611343     0.609784     99.7450%    \n",
      "\n",
      "Eigenvalue Comparison (last 10 modes):\n",
      "Mode   Predicted    Reference    Abs Error    Rel Error   \n",
      "------------------------------------------------------------------\n",
      "41     0.002840     7.422193     7.419353     99.9617%    \n",
      "42     0.002962     7.449484     7.446522     99.9602%    \n",
      "43     0.003221     7.455601     7.452379     99.9568%    \n",
      "44     0.003831     7.508104     7.504273     99.9490%    \n",
      "45     0.004191     7.526791     7.522600     99.9443%    \n",
      "46     0.418315     7.607393     7.189078     94.5012%    \n",
      "47     0.684984     7.614276     6.929292     91.0040%    \n",
      "48     0.781474     7.708104     6.926630     89.8617%    \n",
      "49     0.783050     7.724856     6.941806     89.8632%    \n",
      "50     0.803374     7.834566     7.031192     89.7458%    \n",
      "\n",
      "Overall Statistics (all 50 modes):\n",
      "  Mean Absolute Error:   4.154553\n",
      "  Mean Relative Error:   20227141.4410%\n",
      "  Median Relative Error: 99.9413%\n",
      "  Max Relative Error:    1011352243.9958%\n",
      "  Modes with <5% error:  0/50\n",
      "  Modes with <10% error: 0/50\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "\n",
    "# ==== Final result ====\n",
    "with torch.no_grad():\n",
    "    U_final = model(X)\n",
    "    UKU = U_final.T @ (K @ U_final)\n",
    "    final_eigs = torch.diag(UKU).cpu().numpy()\n",
    "    final_eigs.sort()\n",
    "\n",
    "    # FINAL EVALUATION\n",
    "    abs_error = np.abs(final_eigs - eigvals[:k])\n",
    "    rel_error = abs_error / (np.abs(eigvals[:k]) + 1e-10)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Eigenvalue comparison\n",
    "    print(f\"\\nEigenvalue Comparison (first 10 modes):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<12} {'Reference':<12} {'Abs Error':<12} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 66)\n",
    "    for i in range(min(10, k)):\n",
    "        print(f\"{i+1:<6} {final_eigs[i]:<12.6f} {eigvals[i]:<12.6f} \"\n",
    "              f\"{abs_error[i]:<12.6f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    print(f\"\\nEigenvalue Comparison (last 10 modes):\")\n",
    "    print(f\"{'Mode':<6} {'Predicted':<12} {'Reference':<12} {'Abs Error':<12} {'Rel Error':<12}\")\n",
    "    print(\"-\" * 66)\n",
    "    for i in range(max(0, k-10), k):\n",
    "        print(f\"{i+1:<6} {final_eigs[i]:<12.6f} {eigvals[i]:<12.6f} \"\n",
    "              f\"{abs_error[i]:<12.6f} {rel_error[i]:<12.4%}\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"\\nOverall Statistics (all {k} modes):\")\n",
    "    print(f\"  Mean Absolute Error:   {np.mean(abs_error):.6f}\")\n",
    "    print(f\"  Mean Relative Error:   {np.mean(rel_error):.4%}\")\n",
    "    print(f\"  Median Relative Error: {np.median(rel_error):.4%}\")\n",
    "    print(f\"  Max Relative Error:    {np.max(rel_error):.4%}\")\n",
    "    print(f\"  Modes with <5% error:  {np.sum(rel_error < 0.05)}/{k}\")\n",
    "    print(f\"  Modes with <10% error: {np.sum(rel_error < 0.10)}/{k}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef0315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
