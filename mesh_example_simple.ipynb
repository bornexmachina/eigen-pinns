{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8a717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg\n",
    "from Mesh import Mesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e27da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors (double precision for better numerical stability)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d16402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Laplacian\n",
      "Computing eigen values\n"
     ]
    }
   ],
   "source": [
    "m = Mesh('data/coil_1.2_MM.obj')\n",
    "\n",
    "centroid = m.verts.mean(0)\n",
    "std_max = m.verts.std(0).max()\n",
    "\n",
    "verts_new = (m.verts - centroid)/std_max\n",
    "\n",
    "m = Mesh(verts = verts_new, connectivity = m.connectivity)\n",
    "\n",
    "print('Computing Laplacian')\n",
    "K, M = m.computeLaplacian()\n",
    "\n",
    "# following Finite Elements methodology \n",
    "# K is stiffness matrix, M is mass matrix\n",
    "# The problem to solve becomes \n",
    "# K*u = lambda * M*u\n",
    "print('Computing eigen values')\n",
    "eigvals, eigvecs = linalg.eigh(K,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abff7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send all relevant numpy arrays to torch tensors\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "X = torch.from_numpy(m.verts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653bef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper we used 50 eigenvalues so set k to 50\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network that maps coordinates -> k outputs per node\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=k, hidden=[64,64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last, h, dtype=torch.double))\n",
    "            layers.append(nn.Tanh())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, out_dim, dtype=torch.double))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns (N, k)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "model = MLP().to(device)\n",
    "# Initialize all layers (Xavier), final layer small\n",
    "for name, p in model.named_parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "for p in model.net[-1].parameters():  # last Linear\n",
    "    if p.ndim == 2:\n",
    "        nn.init.normal_(p, std=1e-3)\n",
    "    else:\n",
    "        nn.init.zeros_(p)\n",
    "\n",
    "lr_start = 0.01\n",
    "lr_end = 0.0001\n",
    "max_epochs = 100_000\n",
    "print_every = 1_000\n",
    "loss_history = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_start)\n",
    "decay_factor = (lr_end / lr_start) ** (1 / max_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total loss=2497.429990, eig_loss=0.003614, orth_loss=49.948528\n",
      "Epoch 1000, total loss=2220.907686, eig_loss=4.289153, orth_loss=44.332371\n",
      "Epoch 2000, total loss=2090.293963, eig_loss=8.208283, orth_loss=41.641714\n",
      "Epoch 3000, total loss=1871.309239, eig_loss=19.312839, orth_loss=37.039928\n",
      "Epoch 4000, total loss=1583.541982, eig_loss=47.903692, orth_loss=30.712766\n",
      "Epoch 5000, total loss=1288.096849, eig_loss=86.265382, orth_loss=24.036629\n",
      "Epoch 6000, total loss=2604.043038, eig_loss=175.408242, orth_loss=48.572696\n",
      "Epoch 7000, total loss=1929.525843, eig_loss=143.556768, orth_loss=35.719381\n",
      "Epoch 8000, total loss=1751.863169, eig_loss=127.232020, orth_loss=32.492623\n",
      "Epoch 9000, total loss=1676.351127, eig_loss=118.244459, orth_loss=31.162133\n",
      "Epoch 10000, total loss=1630.239481, eig_loss=114.070206, orth_loss=30.323385\n",
      "Epoch 11000, total loss=1590.172239, eig_loss=113.630764, orth_loss=29.530829\n",
      "Epoch 12000, total loss=1546.511335, eig_loss=116.607044, orth_loss=28.598086\n",
      "Epoch 13000, total loss=1495.427763, eig_loss=122.449008, orth_loss=27.459575\n",
      "Epoch 14000, total loss=1428.876264, eig_loss=129.933393, orth_loss=25.978857\n",
      "Epoch 15000, total loss=1336.047094, eig_loss=139.344758, orth_loss=23.934047\n",
      "Epoch 16000, total loss=1235.966117, eig_loss=152.054527, orth_loss=21.678232\n",
      "Epoch 17000, total loss=1147.398974, eig_loss=163.482260, orth_loss=19.678334\n",
      "Epoch 18000, total loss=1068.685058, eig_loss=171.465685, orth_loss=17.944387\n",
      "Epoch 19000, total loss=944.434832, eig_loss=187.452880, orth_loss=15.139639\n",
      "Epoch 20000, total loss=840.433343, eig_loss=203.645215, orth_loss=12.735763\n",
      "Epoch 21000, total loss=9676.105192, eig_loss=667.400299, orth_loss=180.174098\n",
      "Epoch 22000, total loss=3483.464890, eig_loss=515.280937, orth_loss=59.363679\n",
      "Epoch 23000, total loss=2135.830641, eig_loss=437.762099, orth_loss=33.961371\n",
      "Epoch 24000, total loss=1638.890413, eig_loss=384.860491, orth_loss=25.080598\n",
      "Epoch 25000, total loss=1421.062561, eig_loss=347.821505, orth_loss=21.464821\n",
      "Epoch 26000, total loss=1310.033215, eig_loss=324.083002, orth_loss=19.719004\n",
      "Epoch 27000, total loss=1235.981039, eig_loss=311.431862, orth_loss=18.490984\n",
      "Epoch 28000, total loss=1170.710633, eig_loss=307.008107, orth_loss=17.274051\n",
      "Epoch 29000, total loss=1104.540792, eig_loss=306.555120, orth_loss=15.959713\n",
      "Epoch 30000, total loss=1018.888978, eig_loss=309.674921, orth_loss=14.184281\n",
      "Epoch 31000, total loss=916.244266, eig_loss=314.987129, orth_loss=12.025143\n",
      "Epoch 32000, total loss=790.213696, eig_loss=317.496792, orth_loss=9.454338\n",
      "Epoch 33000, total loss=648.894891, eig_loss=321.634709, orth_loss=6.545204\n",
      "Epoch 34000, total loss=527.157318, eig_loss=328.098873, orth_loss=3.981169\n",
      "Epoch 35000, total loss=437.785082, eig_loss=323.081506, orth_loss=2.294072\n",
      "Epoch 36000, total loss=345.773154, eig_loss=322.831788, orth_loss=0.458827\n",
      "Epoch 37000, total loss=319.825994, eig_loss=301.365781, orth_loss=0.369204\n",
      "Epoch 38000, total loss=302.577378, eig_loss=286.677785, orth_loss=0.317992\n",
      "Epoch 39000, total loss=291.307313, eig_loss=276.919147, orth_loss=0.287763\n",
      "Epoch 40000, total loss=283.645530, eig_loss=269.760768, orth_loss=0.277695\n",
      "Epoch 41000, total loss=278.542342, eig_loss=264.492684, orth_loss=0.280993\n",
      "Epoch 42000, total loss=273.768842, eig_loss=260.733643, orth_loss=0.260704\n",
      "Epoch 43000, total loss=270.522890, eig_loss=258.023147, orth_loss=0.249995\n",
      "Epoch 44000, total loss=268.103327, eig_loss=255.712636, orth_loss=0.247814\n",
      "Epoch 45000, total loss=266.019048, eig_loss=253.738393, orth_loss=0.245613\n",
      "Epoch 46000, total loss=263.542138, eig_loss=252.143857, orth_loss=0.227966\n",
      "Epoch 47000, total loss=261.411238, eig_loss=250.741211, orth_loss=0.213401\n",
      "Epoch 48000, total loss=260.203192, eig_loss=249.572947, orth_loss=0.212605\n",
      "Epoch 49000, total loss=259.294057, eig_loss=248.491413, orth_loss=0.216053\n",
      "Epoch 50000, total loss=258.203773, eig_loss=247.558404, orth_loss=0.212907\n",
      "Epoch 51000, total loss=257.323789, eig_loss=246.703774, orth_loss=0.212400\n",
      "Epoch 52000, total loss=256.611540, eig_loss=245.938541, orth_loss=0.213460\n",
      "Epoch 53000, total loss=255.288617, eig_loss=245.254801, orth_loss=0.200676\n",
      "Epoch 54000, total loss=254.791119, eig_loss=244.523889, orth_loss=0.205345\n",
      "Epoch 55000, total loss=254.093664, eig_loss=243.888182, orth_loss=0.204110\n",
      "Epoch 56000, total loss=253.333507, eig_loss=243.223182, orth_loss=0.202206\n",
      "Epoch 57000, total loss=252.406840, eig_loss=242.588268, orth_loss=0.196371\n",
      "Epoch 58000, total loss=251.610668, eig_loss=242.014358, orth_loss=0.191926\n",
      "Epoch 59000, total loss=251.213411, eig_loss=241.420281, orth_loss=0.195863\n",
      "Epoch 60000, total loss=250.620347, eig_loss=240.923806, orth_loss=0.193931\n",
      "Epoch 61000, total loss=250.137864, eig_loss=240.434421, orth_loss=0.194069\n",
      "Epoch 62000, total loss=249.770174, eig_loss=239.975858, orth_loss=0.195886\n",
      "Epoch 63000, total loss=249.295726, eig_loss=239.553128, orth_loss=0.194852\n",
      "Epoch 64000, total loss=248.518071, eig_loss=239.125429, orth_loss=0.187853\n",
      "Epoch 65000, total loss=248.171519, eig_loss=238.690880, orth_loss=0.189613\n",
      "Epoch 66000, total loss=247.644513, eig_loss=238.289043, orth_loss=0.187109\n",
      "Epoch 67000, total loss=247.437905, eig_loss=237.892873, orth_loss=0.190901\n",
      "Epoch 68000, total loss=246.753241, eig_loss=237.499890, orth_loss=0.185067\n",
      "Epoch 69000, total loss=246.404736, eig_loss=237.102844, orth_loss=0.186038\n",
      "Epoch 70000, total loss=245.970567, eig_loss=236.728339, orth_loss=0.184845\n",
      "Epoch 71000, total loss=245.527537, eig_loss=236.379013, orth_loss=0.182970\n",
      "Epoch 72000, total loss=245.158809, eig_loss=236.020964, orth_loss=0.182757\n",
      "Epoch 73000, total loss=244.880132, eig_loss=235.690611, orth_loss=0.183790\n",
      "Epoch 74000, total loss=244.444026, eig_loss=235.345795, orth_loss=0.181965\n",
      "Epoch 75000, total loss=244.159041, eig_loss=235.048654, orth_loss=0.182208\n",
      "Epoch 76000, total loss=243.796651, eig_loss=234.726881, orth_loss=0.181395\n",
      "Epoch 77000, total loss=243.428744, eig_loss=234.431168, orth_loss=0.179952\n",
      "Epoch 78000, total loss=243.207655, eig_loss=234.135661, orth_loss=0.181440\n",
      "Epoch 79000, total loss=242.804634, eig_loss=233.847304, orth_loss=0.179147\n",
      "Epoch 80000, total loss=242.516349, eig_loss=233.560265, orth_loss=0.179122\n",
      "Epoch 81000, total loss=242.214224, eig_loss=233.290487, orth_loss=0.178475\n",
      "Epoch 82000, total loss=241.969801, eig_loss=233.009983, orth_loss=0.179196\n",
      "Epoch 83000, total loss=241.656673, eig_loss=232.745259, orth_loss=0.178228\n",
      "Epoch 84000, total loss=241.362832, eig_loss=232.478621, orth_loss=0.177684\n",
      "Epoch 85000, total loss=241.074244, eig_loss=232.226243, orth_loss=0.176960\n",
      "Epoch 86000, total loss=240.806139, eig_loss=231.961049, orth_loss=0.176902\n",
      "Epoch 87000, total loss=240.547606, eig_loss=231.709861, orth_loss=0.176755\n",
      "Epoch 88000, total loss=240.261418, eig_loss=231.465311, orth_loss=0.175922\n",
      "Epoch 89000, total loss=240.058059, eig_loss=231.210814, orth_loss=0.176945\n",
      "Epoch 90000, total loss=239.764267, eig_loss=230.983061, orth_loss=0.175624\n",
      "Epoch 91000, total loss=239.484574, eig_loss=230.736811, orth_loss=0.174955\n",
      "Epoch 92000, total loss=239.246811, eig_loss=230.502794, orth_loss=0.174880\n",
      "Epoch 93000, total loss=238.993030, eig_loss=230.271685, orth_loss=0.174427\n",
      "Epoch 94000, total loss=238.780916, eig_loss=230.037133, orth_loss=0.174876\n",
      "Epoch 95000, total loss=238.504063, eig_loss=229.807123, orth_loss=0.173939\n",
      "Epoch 96000, total loss=238.259546, eig_loss=229.585079, orth_loss=0.173489\n",
      "Epoch 97000, total loss=238.033322, eig_loss=229.369745, orth_loss=0.173272\n",
      "Epoch 98000, total loss=237.780754, eig_loss=229.149107, orth_loss=0.172633\n",
      "Epoch 99000, total loss=237.550761, eig_loss=228.933268, orth_loss=0.172350\n",
      "Epoch 100000, total loss=237.323467, eig_loss=228.720839, orth_loss=0.172053\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, max_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    U = model(X)  # N x k\n",
    "\n",
    "    # losses\n",
    "    B = U.T @ (M @ U)        # k x k\n",
    "    orth_loss = torch.norm(B - torch.eye(k, device=device), p='fro')**2\n",
    "    eig_loss = torch.trace(U.T @ (K @ U))\n",
    "\n",
    "    loss = eig_loss + orth_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    if epoch % print_every == 0 or epoch == 1:\n",
    "        approx_vals = torch.diag(U.T @ (K @ U)).detach().cpu().numpy()\n",
    "        print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"total loss={loss.item():.6f}, \"\n",
    "        f\"eig_loss={eig_loss.item():.6f}, \"\n",
    "        f\"orth_loss={orth_loss.item():.6f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfdfc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learned Ritz values (from U^T K U): [0.000645 0.065972 0.245733 0.26045  0.272557]\n",
      "Reference eigenvalues (first k):    [0.       0.007574 0.030308 0.068146 0.121208]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "\n",
    "# ==== Final result ====\n",
    "with torch.no_grad():\n",
    "    U_final = model(X)\n",
    "    UKU = U_final.T @ (K @ U_final)\n",
    "    mu, Wsmall = np.linalg.eigh(UKU.cpu().numpy())\n",
    "    mu = np.real(mu)\n",
    "    # sort\n",
    "    idx = np.argsort(mu)\n",
    "    mu = mu[idx]\n",
    "    print(\"\\nLearned Ritz values (from U^T K U):\", np.round(mu[:5], 6))\n",
    "    print(\"Reference eigenvalues (first k):   \", np.round(eigvals[:5], 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086583db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef0315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
