{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feac19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c734db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(nn.Module):\n",
    "  \"\"\"\n",
    "  Hamiltonian neural networks for solving differential equations https://arxiv.org/pdf/2001.11107\n",
    "  The use of sin(·) instead of more common activation functions, such as Sigmoid(·) and tanh(·), \n",
    "  significantly accelerates the network's convergence to a solution\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def forward(self, x):\n",
    "    return torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd32c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(f, x):\n",
    "    \"\"\"\n",
    "    One-dimensional stationary Schrödinger's equation has the second order derivative\n",
    "    So we have to compute d/dx (d/dx f)\n",
    "    This has to be done explicitly and will not be covered by the loss.backward() which will \n",
    "    actually compute the gradient of the loss with regards to the model parameters theta\n",
    "    \"\"\"\n",
    "    grad_outputs = torch.ones_like(f, device=x.device)\n",
    "    gradient = torch.autograd.grad(outputs=f, inputs=x, grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_grid_points(grid, xL, xR, perturbation_factor):\n",
    "    \"\"\"\n",
    "    For the training, a batch of xi points in the interval [xL, xR] is selected as input. In every training iteration (epoch) the\n",
    "    input points are perturbed by a Gaussian noise to prevent the network from learning the solutions only at fixed points.\n",
    "    \"\"\"\n",
    "    delta = grid[1] - grid[2]\n",
    "\n",
    "    noise = delta * torch.randn_like(grid) * perturbation_factor\n",
    "    perturbed_grid = grid + noise\n",
    "\n",
    "    perturbed_grid[perturbed_grid < xL] = 2*xL - perturbed_grid[perturbed_grid < xL]\n",
    "    perturbed_grid[perturbed_grid > xR] = 2*xR - perturbed_grid[perturbed_grid > xR]\n",
    "\n",
    "    perturbed_grid[0] = xL\n",
    "    perturbed_grid[-1] = xR\n",
    "\n",
    "    perturbed_grid.requires_grad = False\n",
    "\n",
    "    return perturbed_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_function(x, xL, xR):\n",
    "    \"\"\"\n",
    "    Selecting an appropriate parametric function g(x) is necessary for enforcing boundary conditions. \n",
    "    The following parametric equation enforces a f (xL) = f (xR) = 0 boundary conditions\n",
    "    \"\"\"\n",
    "    return (1 - torch.exp(-(x - xL))) * (1 - torch.exp(-(x - xR)))\n",
    "\n",
    "\n",
    "def parametric_trick(x, xL, xR, boundary_value, neural_net):\n",
    "    \"\"\"\n",
    "    The predicted eigenfunctions are defined using a parametric trick, i.e are not directly computed by the neural network\n",
    "    The neural network returns a tuple: network_prediction and learnable_lambda\n",
    "    \"\"\"\n",
    "    network_prediction, _ = neural_net(x)\n",
    "    g = parametric_function(x, xL, xR)\n",
    "    return boundary_value + g * network_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262116be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_schroedinger_loss_residual_and_hamiltonian(x, psi, E, V):\n",
    "    \"\"\"\n",
    "    Schrödingers loss is the mean of the residual. Hamiltonian is used for verification. \n",
    "    The main reason to couple the computations is to use only one autograd pass\n",
    "    \"\"\"\n",
    "    psi_dx = compute_gradient(psi, x)\n",
    "    psi_ddx = compute_gradient(psi_dx, x)\n",
    "\n",
    "    residual = -0.5 * psi_ddx + (V - E) * psi\n",
    "    schroeddinger_loss = (residual.pow(2)).mean()\n",
    "    hamiltonian = -0.5 * psi_ddx + V * psi\n",
    "\n",
    "    return schroeddinger_loss, residual, hamiltonian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcdc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantum_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Network for the 1D PINN task\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=10, symmetry=True):\n",
    "        super().__init__()\n",
    "        self.symmetry = symmetry\n",
    "\n",
    "        self.activation = Sin()\n",
    "        self.input = nn.Linear(1, 1)\n",
    "        self.first_hidden = nn.Linear(2, hidden_dim)\n",
    "        self.second_hidden = nn.Linear(hidden_dim + 1, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim + 1, 1)\n",
    "\n",
    "    def forward(self, t):\n",
    "        learnable_lambda = self.input(torch.ones_like(t))\n",
    "\n",
    "        first_hidden_symmetric = self.activation(self.first_hidden(torch.cat((t, learnable_lambda), dim=1)))\n",
    "        first_hidden_antisymmetric = self.activation(self.first_hiden(torch.cat((-t, learnable_lambda), dim=1)))\n",
    "\n",
    "        secondd_hidden_symmetric = self.activation(self.second_hidden(torch.cat((first_hidden_symmetric, learnable_lambda), dim=1)))\n",
    "        second_hidden_antisymmetric = self.activation(self.second_hidden(torch.cat((first_hidden_antisymmetric, learnable_lambda), dim=1)))\n",
    "\n",
    "        if self.symmetry:\n",
    "            network_prediction = self.output(torch.cat((secondd_hidden_symmetric + second_hidden_antisymmetric, learnable_lambda), dim=1))\n",
    "        else:\n",
    "            network_prediction = self.output(torch.cat((secondd_hidden_symmetric - second_hidden_antisymmetric, learnable_lambda), dim=1))\n",
    "\n",
    "        return network_prediction, learnable_lambda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
