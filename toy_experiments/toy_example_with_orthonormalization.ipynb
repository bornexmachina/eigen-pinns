{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88ab4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58cb777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors (double precision for better numerical stability)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c306c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference eigs: [0.038217 0.056592 0.086685]\n"
     ]
    }
   ],
   "source": [
    "####### inputs\n",
    "N, k = 20, 3  # toy size\n",
    "# random SPD matrices K, M\n",
    "A = np.random.randn(N, N)\n",
    "K = A.T @ A + np.eye(N)   # make SPD\n",
    "B = np.random.randn(N, N)\n",
    "M = B.T @ B + np.eye(N)   # make SPD\n",
    "\n",
    "K = torch.from_numpy(K).to(device)\n",
    "M = torch.from_numpy(M).to(device)\n",
    "\n",
    "# reference solution\n",
    "w_all, V_all = linalg.eigh(K.cpu().numpy(), M.cpu().numpy())\n",
    "print(\"Reference eigs:\", np.round(w_all[:k], 6))\n",
    "\n",
    "\n",
    "X = torch.randn(N, 3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9306d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network that maps coordinates -> k outputs per node\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=k, hidden=[64,64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last, h, dtype=torch.double))\n",
    "            layers.append(nn.Tanh())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, out_dim, dtype=torch.double))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns (N, k)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "model = MLP().to(device)\n",
    "# initialize final layer small\n",
    "for name, p in model.named_parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beaf42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20_000\n",
    "print_every = 1_000\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5411970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: given A (N x k), return M-orthonormalized U = A (A^T M A)^{-1/2}\n",
    "def m_orthonormalize(A, M):\n",
    "    # A: (N, k), M: (N, N)\n",
    "    # compute B = A^T M A (k x k)\n",
    "    B = A.T @ (M @ A)  # k x k\n",
    "    # symmetrize B\n",
    "    B = 0.5*(B + B.T)\n",
    "    # compute inverse sqrt of B via eigendecomposition (k small)\n",
    "    s, Q = torch.linalg.eigh(B)  # s are eigenvalues\n",
    "    # regularize small eigenvalues\n",
    "    s_clamped = torch.clamp(s, min=1e-12)\n",
    "    inv_sqrt = Q @ torch.diag(1.0/torch.sqrt(s_clamped)) @ Q.T\n",
    "    U = A @ inv_sqrt\n",
    "    return U, B, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b50429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1, loss(trace)=3.954603, approx_vals=[0.776102 1.130515 2.047986]\n",
      "Epoch 1000, loss(trace)=0.533638, approx_vals=[0.172237 0.190246 0.171154]\n",
      "Epoch 2000, loss(trace)=0.364480, approx_vals=[0.077848 0.143504 0.143128]\n",
      "Epoch 3000, loss(trace)=0.306609, approx_vals=[0.078265 0.09962  0.128724]\n",
      "Epoch 4000, loss(trace)=0.254188, approx_vals=[0.086205 0.080382 0.087601]\n",
      "Epoch 5000, loss(trace)=0.183291, approx_vals=[0.049457 0.074871 0.058963]\n",
      "Epoch 6000, loss(trace)=0.184610, approx_vals=[0.048033 0.07462  0.061957]\n",
      "Epoch 7000, loss(trace)=0.181764, approx_vals=[0.047927 0.074351 0.059485]\n",
      "Epoch 8000, loss(trace)=0.181684, approx_vals=[0.047822 0.073946 0.059917]\n",
      "Epoch 9000, loss(trace)=0.182084, approx_vals=[0.048197 0.073847 0.060039]\n",
      "Epoch 10000, loss(trace)=0.182961, approx_vals=[0.048166 0.073447 0.061347]\n",
      "Epoch 11000, loss(trace)=0.182699, approx_vals=[0.048333 0.07391  0.060456]\n",
      "Epoch 12000, loss(trace)=0.181848, approx_vals=[0.048607 0.072488 0.060753]\n",
      "Epoch 13000, loss(trace)=0.182275, approx_vals=[0.049069 0.072524 0.060681]\n",
      "Epoch 14000, loss(trace)=0.186213, approx_vals=[0.049905 0.073446 0.062862]\n",
      "Epoch 15000, loss(trace)=0.182262, approx_vals=[0.049764 0.071546 0.060952]\n",
      "Epoch 16000, loss(trace)=0.181662, approx_vals=[0.049827 0.070944 0.060891]\n",
      "Epoch 17000, loss(trace)=0.182056, approx_vals=[0.050041 0.07077  0.061245]\n",
      "Epoch 18000, loss(trace)=0.183356, approx_vals=[0.050751 0.070657 0.061948]\n",
      "Epoch 19000, loss(trace)=0.181702, approx_vals=[0.050661 0.070127 0.060914]\n",
      "Epoch 20000, loss(trace)=0.181602, approx_vals=[0.050949 0.06982  0.060832]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, max_epochs+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    A = model(X)  # N x k\n",
    "    U, B, s = m_orthonormalize(A, M)  # U is M-orthonormal\n",
    "    # compute objective: trace(U^T K U) -> equals sum of Rayleighs for columns\n",
    "    UK = U.T @ (K @ U)\n",
    "    # symmetrize for numerical safety\n",
    "    UK = 0.5*(UK + UK.T)\n",
    "    loss = torch.trace(UK)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.item())\n",
    "    if epoch % print_every == 0 or epoch==1:\n",
    "        # compute approximate eigenvalues by Rayleigh on current U\n",
    "        with torch.no_grad():\n",
    "            # the diagonal entries of UK are the Rayleigh quotients for each column if columns are M-orthonormal\n",
    "            approx_vals = torch.diag(UK).cpu().numpy()\n",
    "        print(f\"Epoch {epoch:4d}, loss(trace)={loss.item():.6f}, approx_vals={np.round(approx_vals,6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c13e4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of U.t @ K @ U is: torch.Size([3, 3])\n",
      "\n",
      "Learned Ritz values (from U^T K U): [0.038219 0.056608 0.086786]\n",
      "Reference eigenvalues (first k):    [0.038217 0.056592 0.086685]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    A_final = model(X)\n",
    "    U_final, B_final, s_final = m_orthonormalize(A_final, M)\n",
    "    UK_final = U_final.T @ (K @ U_final)\n",
    "\n",
    "    print(f\"The shape of U.t @ K @ U is: {UK_final.shape}\")\n",
    "\n",
    "    approx_eigs = np.round(torch.diag(UK_final).cpu().numpy(), 8)\n",
    "    # For better comparison, we can compute Ritz values from subspace U by solving small generalized eigenproblem\n",
    "    # (U^T K U) c = mu (U^T M U) c, but U^T M U = I so just eig of UK_final\n",
    "    mu, Wsmall = np.linalg.eigh(UK_final.cpu().numpy())\n",
    "    mu = np.real(mu)\n",
    "    # sort\n",
    "    idx = np.argsort(mu)\n",
    "    mu = mu[idx]\n",
    "    print(\"\\nLearned Ritz values (from U^T K U):\", np.round(mu, 6))\n",
    "    print(\"Reference eigenvalues (first k):   \", np.round(w_all[:k], 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c3d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff7f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33086abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326062b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltapinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
